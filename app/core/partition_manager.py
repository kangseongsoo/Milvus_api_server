"""
Milvus íŒŒí‹°ì…˜ ë¡œë“œ ê´€ë¦¬ì
- FastAPI ì‹œì‘ ì‹œ ì»¬ë ‰ì…˜ ì „ì²´ ë¡œë“œ
- ì‹ ê·œ íŒŒí‹°ì…˜ ì‹¤ì‹œê°„ ë¡œë“œ
- íŒŒí‹°ì…˜ ì–¸ë¡œë“œ ë° ë©”ëª¨ë¦¬ ê´€ë¦¬
"""

import asyncio
import logging
import psutil
from typing import Dict, Set, Optional
from pymilvus import Collection
from pymilvus.exceptions import SchemaNotReadyException
from datetime import datetime, timedelta
from app.config import settings

logger = logging.getLogger(__name__)


class MilvusPartitionManager:
    """Milvus íŒŒí‹°ì…˜ ë¡œë“œ ë° ê´€ë¦¬ (TTL + ë©”ëª¨ë¦¬ ì„ê³„ê°’ ê¸°ë°˜)"""
    
    def __init__(self):
        self.loaded_partitions: Dict[str, Set[str]] = {}  # {collection_name: {partition_names}}
        self.partition_load_time: Dict[str, datetime] = {}  # ë¡œë“œ ì‹œê°„ ì¶”ì 
        self.last_access_time: Dict[str, datetime] = {}  # ë§ˆì§€ë§‰ ì ‘ê·¼ ì‹œê°„ (TTLìš©)
        self.partition_locks: Dict[str, asyncio.Lock] = {}  # íŒŒí‹°ì…˜ë³„ Lock (ë™ì‹œ ë¡œë“œ ë°©ì§€)
        self._cleanup_running = False  # cleanup ë£¨í”„ ìƒíƒœ
        
    async def preload_collection(self, collection_name: str):
        """
        FastAPI ì‹œì‘ ì‹œ ì»¬ë ‰ì…˜ì˜ ëª¨ë“  íŒŒí‹°ì…˜ ë¡œë“œ
        
        Args:
            collection_name: ë¡œë“œí•  ì»¬ë ‰ì…˜ëª… (ì˜ˆ: "collection_chatty")
        """
        try:
            logger.info(f"ğŸ”„ Starting preload for collection: {collection_name}")
            start_time = datetime.now()
            
            # ì»¬ë ‰ì…˜ ì—°ê²°
            collection = Collection(name=collection_name)
            
            # ëª¨ë“  íŒŒí‹°ì…˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            partitions = collection.partitions
            partition_names = [p.name for p in partitions if p.name != "_default"]
            
            if not partition_names:
                logger.warning(f"âš ï¸ No partitions found in {collection_name}")
                self.loaded_partitions[collection_name] = set()
                return
            
            logger.info(f"ğŸ“¦ Found {len(partition_names)} partitions to load")
            
            # ëª¨ë“  íŒŒí‹°ì…˜ ë¡œë“œ (ë³‘ë ¬ ì²˜ë¦¬)
            await self._load_partitions_parallel(collection, partition_names)
            
            # ë¡œë“œëœ íŒŒí‹°ì…˜ ì¶”ì 
            self.loaded_partitions[collection_name] = set(partition_names)
            
            elapsed_time = (datetime.now() - start_time).total_seconds()
            logger.info(f"âœ… Preload completed in {elapsed_time:.2f}s")
            logger.info(f"   - Collection: {collection_name}")
            logger.info(f"   - Partitions loaded: {len(partition_names)}")
            logger.info(f"   - Estimated memory: ~{len(partition_names) * 25}GB")
            
        except SchemaNotReadyException as e:
            logger.warning(f"âš ï¸ Collection '{collection_name}' does not exist - skipping preload")
            return
        except Exception as e:
            logger.error(f"âŒ Failed to preload collection {collection_name}: {e}")
            raise
    
    async def _load_partitions_parallel(
        self, 
        collection: Collection, 
        partition_names: list[str],
        batch_size: int = 5
    ):
        """
        íŒŒí‹°ì…˜ ë³‘ë ¬ ë¡œë“œ (ë°°ì¹˜ ë‹¨ìœ„)
        
        Args:
            collection: Milvus ì»¬ë ‰ì…˜
            partition_names: ë¡œë“œí•  íŒŒí‹°ì…˜ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
            batch_size: ë™ì‹œ ë¡œë“œí•  íŒŒí‹°ì…˜ ìˆ˜
        """
        total = len(partition_names)
        
        for i in range(0, total, batch_size):
            batch = partition_names[i:i+batch_size]
            batch_num = i // batch_size + 1
            total_batches = (total + batch_size - 1) // batch_size
            
            logger.info(f"ğŸ”„ Loading batch {batch_num}/{total_batches}: {len(batch)} partitions")
            
            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë™ì‹œ ë¡œë“œ
            tasks = [
                self._load_single_partition(collection, pname) 
                for pname in batch
            ]
            await asyncio.gather(*tasks)
    
    async def _load_single_partition(self, collection: Collection, partition_name: str):
        """ë‹¨ì¼ íŒŒí‹°ì…˜ ë¡œë“œ"""
        try:
            start = datetime.now()
            
            # ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            partition = collection.partition(partition_name)
            try:
                if hasattr(partition, 'is_loaded') and partition.is_loaded:
                    logger.debug(f"   â­ï¸  Already loaded: {partition_name}")
                    return
            except:
                # is_loaded ì†ì„±ì´ ì—†ê±°ë‚˜ ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¬´ì‹œí•˜ê³  ë¡œë“œ ì§„í–‰
                pass
            
            # íŒŒí‹°ì…˜ ë¡œë“œ
            collection.load(partition_names=[partition_name])
            
            # ë¡œë“œ ì‹œê°„ ê¸°ë¡
            elapsed = (datetime.now() - start).total_seconds()
            self.partition_load_time[partition_name] = datetime.now()
            
            logger.info(f"   âœ… Loaded {partition_name} in {elapsed:.2f}s ({partition.num_entities:,} entities)")
            
        except Exception as e:
            logger.error(f"   âŒ Failed to load {partition_name}: {e}")
    
    async def load_new_partition(self, collection_name: str, partition_name: str):
        """
        ìƒˆ íŒŒí‹°ì…˜ ì‹¤ì‹œê°„ ë¡œë“œ (ë´‡ ì¶”ê°€ ì‹œ)
        
        Args:
            collection_name: ì»¬ë ‰ì…˜ëª…
            partition_name: ìƒˆë¡œìš´ íŒŒí‹°ì…˜ëª…
        """
        try:
            logger.info(f"ğŸ†• Loading new partition: {collection_name}/{partition_name}")
            
            collection = Collection(name=collection_name)
            await self._load_single_partition(collection, partition_name)
            
            # ì¶”ì  ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            if collection_name not in self.loaded_partitions:
                self.loaded_partitions[collection_name] = set()
            self.loaded_partitions[collection_name].add(partition_name)
            
            logger.info(f"âœ… New partition loaded and tracked: {partition_name}")
            
        except Exception as e:
            logger.error(f"âŒ Failed to load new partition {partition_name}: {e}")
            raise
    
    async def unload_partition(self, collection_name: str, partition_name: str):
        """
        íŒŒí‹°ì…˜ ì–¸ë¡œë“œ (ë´‡ ì‚­ì œ ì‹œ)
        
        Args:
            collection_name: ì»¬ë ‰ì…˜ëª…
            partition_name: ì‚­ì œí•  íŒŒí‹°ì…˜ëª…
        """
        try:
            logger.info(f"ğŸ—‘ï¸  Unloading partition: {collection_name}/{partition_name}")
            
            collection = Collection(name=collection_name)
            
            # íŒŒí‹°ì…˜ ì–¸ë¡œë“œ
            partition = collection.partition(partition_name)
            try:
                if hasattr(partition, 'is_loaded') and partition.is_loaded:
                    collection.release(partition_names=[partition_name])
                    logger.info(f"   âœ… Released memory for {partition_name}")
            except:
                # is_loaded ì†ì„±ì´ ì—†ê±°ë‚˜ ì˜¤ë¥˜ ë°œìƒ ì‹œ ê°•ì œ ì–¸ë¡œë“œ
                collection.release(partition_names=[partition_name])
                logger.info(f"   âœ… Released memory for {partition_name}")
            
            # ì¶”ì  ë¦¬ìŠ¤íŠ¸ì—ì„œ ì œê±°
            if collection_name in self.loaded_partitions:
                self.loaded_partitions[collection_name].discard(partition_name)
            
            # ë¡œë“œ ì‹œê°„ ê¸°ë¡ ì œê±°
            self.partition_load_time.pop(partition_name, None)
            
            logger.info(f"âœ… Partition unloaded: {partition_name}")
            
        except Exception as e:
            logger.error(f"âŒ Failed to unload partition {partition_name}: {e}")
            raise
    
    def get_loaded_partitions(self, collection_name: str) -> Set[str]:
        """ë¡œë“œëœ íŒŒí‹°ì…˜ ëª©ë¡ ì¡°íšŒ"""
        return self.loaded_partitions.get(collection_name, set())
    
    def is_partition_loaded(self, collection_name: str, partition_name: str) -> bool:
        """íŒŒí‹°ì…˜ ë¡œë“œ ìƒíƒœ í™•ì¸"""
        return partition_name in self.loaded_partitions.get(collection_name, set())
    
    def get_load_time(self, partition_name: str) -> datetime | None:
        """íŒŒí‹°ì…˜ ë¡œë“œ ì‹œê°„ ì¡°íšŒ"""
        return self.partition_load_time.get(partition_name)
    
    def _get_partition_key(self, collection_name: str, partition_name: str) -> str:
        """íŒŒí‹°ì…˜ ê³ ìœ  í‚¤ ìƒì„±"""
        return f"{collection_name}/{partition_name}"
    
    def _get_lock(self, collection_name: str, partition_name: str) -> asyncio.Lock:
        """íŒŒí‹°ì…˜ë³„ Lock ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ìƒì„±)"""
        key = self._get_partition_key(collection_name, partition_name)
        if key not in self.partition_locks:
            self.partition_locks[key] = asyncio.Lock()
        return self.partition_locks[key]
    
    async def ensure_partition_loaded(
        self, 
        collection_name: str, 
        partition_name: str,
        force_reload: bool = False
    ) -> bool:
        """
        íŒŒí‹°ì…˜ì´ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ë¡œë“œ (ë™ì‹œ ë¡œë“œ ë°©ì§€)
        
        Args:
            collection_name: ì»¬ë ‰ì…˜ëª…
            partition_name: íŒŒí‹°ì…˜ëª…
            force_reload: ê°•ì œ ì¬ë¡œë“œ ì—¬ë¶€
        
        Returns:
            ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        
        Note:
            - Lockì„ ì‚¬ìš©í•˜ì—¬ ë™ì¼ íŒŒí‹°ì…˜ ì¤‘ë³µ ë¡œë“œ ë°©ì§€
            - ë§ˆì§€ë§‰ ì ‘ê·¼ ì‹œê°„ ìë™ ê°±ì‹  (TTLìš©)
        """
        key = self._get_partition_key(collection_name, partition_name)
        lock = self._get_lock(collection_name, partition_name)
        
        # ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆìœ¼ë©´ ì ‘ê·¼ ì‹œê°„ë§Œ ê°±ì‹ 
        if not force_reload and self.is_partition_loaded(collection_name, partition_name):
            self.last_access_time[key] = datetime.now()
            logger.debug(f"âœ… Partition already loaded: {key}")
            return True
        
        # Lock íšë“í•˜ì—¬ ë™ì‹œ ë¡œë“œ ë°©ì§€
        async with lock:
            # Lock ëŒ€ê¸° ì¤‘ ë‹¤ë¥¸ ìŠ¤ë ˆë“œê°€ ë¡œë“œí–ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¬í™•ì¸
            if not force_reload and self.is_partition_loaded(collection_name, partition_name):
                self.last_access_time[key] = datetime.now()
                logger.debug(f"âœ… Partition loaded by another task: {key}")
                return True
            
            # ë©”ëª¨ë¦¬ ì²´í¬ í›„ í•„ìš” ì‹œ ì •ë¦¬
            await self._check_memory_and_cleanup()
            
            # íŒŒí‹°ì…˜ ë¡œë“œ
            try:
                logger.info(f"ğŸ”„ Loading partition: {key}")
                start_time = datetime.now()
                
                collection = Collection(name=collection_name)
                partition = collection.partition(partition_name)
                
                # ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆìœ¼ë©´ ìŠ¤í‚µ
                try:
                    if not force_reload and hasattr(partition, 'is_loaded') and partition.is_loaded:
                        logger.debug(f"   â­ï¸  Already loaded: {partition_name}")
                    else:
                        collection.load(partition_names=[partition_name])
                except:
                    # is_loaded ì†ì„±ì´ ì—†ê±°ë‚˜ ì˜¤ë¥˜ ë°œìƒ ì‹œ ê°•ì œ ë¡œë“œ
                    collection.load(partition_names=[partition_name])
                
                # ì¶”ì  ì •ë³´ ì—…ë°ì´íŠ¸
                if collection_name not in self.loaded_partitions:
                    self.loaded_partitions[collection_name] = set()
                self.loaded_partitions[collection_name].add(partition_name)
                
                now = datetime.now()
                self.partition_load_time[key] = now
                self.last_access_time[key] = now
                
                elapsed = (datetime.now() - start_time).total_seconds()
                logger.info(f"âœ… Partition loaded in {elapsed:.2f}s: {key} ({partition.num_entities:,} entities)")
                
                return True
                
            except SchemaNotReadyException:
                logger.warning(f"âš ï¸ Collection '{collection_name}' does not exist")
                return False
            except Exception as e:
                logger.error(f"âŒ Failed to load partition {key}: {e}")
                return False
    
    async def auto_cleanup_loop(self):
        """
        ë°±ê·¸ë¼ìš´ë“œ: TTL ê¸°ë°˜ ìë™ ì •ë¦¬ ë£¨í”„
        - ì¼ì • ì‹œê°„ë§ˆë‹¤ ë¯¸ì‚¬ìš© íŒŒí‹°ì…˜ ì–¸ë¡œë“œ
        - ë©”ëª¨ë¦¬ ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ê°•ì œ ì •ë¦¬
        """
        self._cleanup_running = True
        logger.info(f"ğŸ”„ Auto cleanup loop started (interval: {settings.CLEANUP_INTERVAL_SECONDS}s, TTL: {settings.PARTITION_TTL_MINUTES}m)")
        
        try:
            while self._cleanup_running:
                await asyncio.sleep(settings.CLEANUP_INTERVAL_SECONDS)
                
                try:
                    # 1. TTL ê¸°ë°˜ ì •ë¦¬
                    await self._cleanup_by_ttl()
                    
                    # 2. ë©”ëª¨ë¦¬ ì„ê³„ê°’ ì²´í¬
                    await self._check_memory_and_cleanup()
                    
                except Exception as e:
                    logger.error(f"âŒ Cleanup error: {e}")
        
        finally:
            self._cleanup_running = False
            logger.info("ğŸ›‘ Auto cleanup loop stopped")
    
    async def stop_cleanup_loop(self):
        """Cleanup ë£¨í”„ ì¤‘ì§€"""
        self._cleanup_running = False
    
    async def sync_partition_states(self, collection_names: list[str] = None):
        """
        FastAPI ì‹œì‘ ì‹œ Milvus íŒŒí‹°ì…˜ ìƒíƒœì™€ ë™ê¸°í™”
        
        Args:
            collection_names: ë™ê¸°í™”í•  ì»¬ë ‰ì…˜ ëª©ë¡ (Noneì´ë©´ ëª¨ë“  ì»¬ë ‰ì…˜ ìë™ ì¡°íšŒ)
        
        Note:
            - Milvusì— ì‹¤ì œë¡œ ë¡œë“œëœ íŒŒí‹°ì…˜ë“¤ì„ FastAPI ë©”ëª¨ë¦¬ì— ë™ê¸°í™”
            - FastAPI ì¬ì‹œì‘ í›„ ìƒíƒœ ë¶ˆì¼ì¹˜ ë¬¸ì œ í•´ê²°
            - ë™ì ìœ¼ë¡œ ëª¨ë“  ì»¬ë ‰ì…˜ì„ ìë™ìœ¼ë¡œ ì°¾ì•„ì„œ ì²˜ë¦¬
        """
        try:
            logger.info("ğŸ”„ Starting partition state synchronization...")
            start_time = datetime.now()
            
            if collection_names is None:
                # Milvusì—ì„œ ëª¨ë“  ì»¬ë ‰ì…˜ì„ ë™ì ìœ¼ë¡œ ì¡°íšŒ
                logger.info("ğŸ“‹ Discovering all collections in Milvus...")
                from pymilvus import utility
                all_collections = utility.list_collections()
                
                # ì‹œìŠ¤í…œ ì»¬ë ‰ì…˜ ì œì™¸ (í•„ìš”ì‹œ)
                collection_names = [name for name in all_collections if not name.startswith('_')]
                
                if not collection_names:
                    logger.info("â­ï¸  No collections found - skipping synchronization")
                    return {
                        "collections_checked": 0,
                        "partitions_synced": 0,
                        "sync_time_seconds": 0,
                        "estimated_memory_gb": 0
                    }
            
            synced_count = 0
            collections_with_loaded_partitions = 0
            total_partitions_checked = 0
            
            # ëŒ€ëŸ‰ ì»¬ë ‰ì…˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ ê°„ê²°í•œ ë¡œê·¸
            logger.info(f"ğŸ“¦ Processing {len(collection_names)} collections...")
            
            for i, collection_name in enumerate(collection_names, 1):
                try:
                    collection = Collection(name=collection_name)
                    
                    # ì»¬ë ‰ì…˜ì˜ ëª¨ë“  íŒŒí‹°ì…˜ ì¡°íšŒ
                    partitions = collection.partitions
                    partition_names = [p.name for p in partitions if p.name != "_default"]
                    
                    if not partition_names:
                        continue
                    
                    total_partitions_checked += len(partition_names)
                    collection_loaded_count = 0
                    
                    for partition_name in partition_names:
                        try:
                            partition = collection.partition(partition_name)
                            
                            # Milvusì—ì„œ ì‹¤ì œ ë¡œë“œ ìƒíƒœ í™•ì¸
                            if hasattr(partition, 'is_loaded') and partition.is_loaded:
                                # FastAPI ë©”ëª¨ë¦¬ì— ë™ê¸°í™”
                                if collection_name not in self.loaded_partitions:
                                    self.loaded_partitions[collection_name] = set()
                                
                                self.loaded_partitions[collection_name].add(partition_name)
                                
                                # ì ‘ê·¼ ì‹œê°„ì„ í˜„ì¬ ì‹œê°„ìœ¼ë¡œ ì„¤ì • (TTL ì •ë¦¬ ë°©ì§€)
                                key = self._get_partition_key(collection_name, partition_name)
                                self.last_access_time[key] = datetime.now()
                                
                                # ë¡œë“œ ì‹œê°„ë„ í˜„ì¬ ì‹œê°„ìœ¼ë¡œ ì„¤ì •
                                self.partition_load_time[key] = datetime.now()
                                
                                synced_count += 1
                                collection_loaded_count += 1
                                
                        except Exception as partition_error:
                            logger.debug(f"Failed to check partition {collection_name}/{partition_name}: {partition_error}")
                            continue
                    
                    # ì»¬ë ‰ì…˜ë³„ ìš”ì•½ ë¡œê·¸ (ë¡œë“œëœ íŒŒí‹°ì…˜ì´ ìˆëŠ” ê²½ìš°ë§Œ)
                    if collection_loaded_count > 0:
                        collections_with_loaded_partitions += 1
                        logger.info(f"   [{i:3d}/{len(collection_names)}] {collection_name}: {collection_loaded_count}/{len(partition_names)} partitions loaded")
                
                except SchemaNotReadyException:
                    logger.debug(f"Collection '{collection_name}' does not exist - skipping")
                    continue
                except Exception as collection_error:
                    logger.debug(f"Failed to sync collection {collection_name}: {collection_error}")
                    continue
            
            elapsed_time = (datetime.now() - start_time).total_seconds()
            logger.info(f"âœ… Partition state synchronization completed in {elapsed_time:.2f}s")
            logger.info(f"   - Collections checked: {len(collection_names)}")
            logger.info(f"   - Collections with loaded partitions: {collections_with_loaded_partitions}")
            logger.info(f"   - Total partitions checked: {total_partitions_checked}")
            logger.info(f"   - Partitions synced: {synced_count}")
            logger.info(f"   - Estimated memory: ~{synced_count * 25}GB")
            
            return {
                "collections_checked": len(collection_names),
                "collections_with_loaded_partitions": collections_with_loaded_partitions,
                "total_partitions_checked": total_partitions_checked,
                "partitions_synced": synced_count,
                "sync_time_seconds": elapsed_time,
                "estimated_memory_gb": synced_count * 25
            }
            
        except Exception as e:
            logger.error(f"âŒ Failed to sync partition states: {e}")
            raise
    
    async def _cleanup_by_ttl(self):
        """TTL ê¸°ë°˜ íŒŒí‹°ì…˜ ì–¸ë¡œë“œ"""
        now = datetime.now()
        ttl_threshold = timedelta(minutes=settings.PARTITION_TTL_MINUTES)
        
        to_unload = []
        
        for key, last_access in list(self.last_access_time.items()):
            if now - last_access > ttl_threshold:
                to_unload.append(key)
        
        if to_unload:
            logger.info(f"ğŸ—‘ï¸  TTL expired: unloading {len(to_unload)} partitions")
            
            for key in to_unload:
                try:
                    collection_name, partition_name = key.split("/", 1)
                    await self.unload_partition(collection_name, partition_name)
                except Exception as e:
                    logger.error(f"âŒ Failed to unload {key}: {e}")
    
    async def _check_memory_and_cleanup(self):
        """ë©”ëª¨ë¦¬ ì„ê³„ê°’ ì²´í¬ ë° ê°•ì œ ì •ë¦¬"""
        memory = psutil.virtual_memory()
        memory_percent = memory.percent
        
        if memory_percent > settings.MEMORY_THRESHOLD_PERCENT:
            logger.warning(f"âš ï¸ Memory threshold exceeded: {memory_percent:.1f}% > {settings.MEMORY_THRESHOLD_PERCENT}%")
            
            # ê°€ì¥ ì˜¤ë˜ëœ íŒŒí‹°ì…˜ë¶€í„° ì–¸ë¡œë“œ
            sorted_partitions = sorted(
                self.last_access_time.items(),
                key=lambda x: x[1]
            )
            
            unload_count = max(1, len(sorted_partitions) // 4)  # ìµœì†Œ 25% ì–¸ë¡œë“œ
            logger.info(f"ğŸ—‘ï¸  Force unloading {unload_count} oldest partitions")
            
            for key, _ in sorted_partitions[:unload_count]:
                try:
                    collection_name, partition_name = key.split("/", 1)
                    await self.unload_partition(collection_name, partition_name)
                    
                    # ë©”ëª¨ë¦¬ ì¬í™•ì¸
                    memory = psutil.virtual_memory()
                    if memory.percent < settings.MEMORY_THRESHOLD_PERCENT:
                        logger.info(f"âœ… Memory stabilized: {memory.percent:.1f}%")
                        break
                except Exception as e:
                    logger.error(f"âŒ Failed to unload {key}: {e}")
    
    def get_partition_stats(self) -> dict:
        """
        íŒŒí‹°ì…˜ í†µê³„ ì¡°íšŒ (Health Checkìš©)
        
        Returns:
            í†µê³„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        memory = psutil.virtual_memory()
        
        # ê°€ì¥ ì˜¤ë˜ëœ íŒŒí‹°ì…˜ ì°¾ê¸°
        oldest_partition = None
        oldest_time = None
        if self.last_access_time:
            oldest_key = min(self.last_access_time, key=self.last_access_time.get)
            oldest_time = self.last_access_time[oldest_key]
            oldest_partition = oldest_key
        
        # ë¡œë“œëœ íŒŒí‹°ì…˜ ëª©ë¡
        all_loaded = []
        for collection_name, partitions in self.loaded_partitions.items():
            for partition_name in partitions:
                key = self._get_partition_key(collection_name, partition_name)
                last_access = self.last_access_time.get(key)
                all_loaded.append({
                    "key": key,
                    "last_access": last_access.isoformat() if last_access else None,
                    "minutes_ago": int((datetime.now() - last_access).total_seconds() / 60) if last_access else None
                })
        
        return {
            "loaded_count": sum(len(partitions) for partitions in self.loaded_partitions.values()),
            "memory": {
                "total_gb": round(memory.total / (1024**3), 2),
                "available_gb": round(memory.available / (1024**3), 2),
                "used_gb": round(memory.used / (1024**3), 2),
                "percent": round(memory.percent, 1),
                "threshold_percent": settings.MEMORY_THRESHOLD_PERCENT
            },
            "oldest_partition": {
                "key": oldest_partition,
                "last_access": oldest_time.isoformat() if oldest_time else None,
                "minutes_ago": int((datetime.now() - oldest_time).total_seconds() / 60) if oldest_time else None
            } if oldest_partition else None,
            "loaded_partitions": all_loaded,
            "config": {
                "ttl_minutes": settings.PARTITION_TTL_MINUTES,
                "cleanup_interval_seconds": settings.CLEANUP_INTERVAL_SECONDS,
                "max_concurrent_loads": settings.MAX_CONCURRENT_LOADS
            }
        }


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
partition_manager = MilvusPartitionManager()

