"""
Redis ê¸°ë°˜ Milvus íŒŒí‹°ì…˜ ë§¤ë‹ˆì €
ì˜êµ¬ ìƒíƒœ ì €ì¥ ë° TTL ê´€ë¦¬
"""
import asyncio
from datetime import datetime, timedelta
from typing import Dict, Set, List, Optional, Any
from pymilvus import Collection, connections
from app.config import settings
from app.core.redis_client import redis_client
from app.utils.logger import setup_logger
import psutil

logger = setup_logger(__name__)


class RedisMilvusPartitionManager:
    """Redis ê¸°ë°˜ Milvus íŒŒí‹°ì…˜ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.partition_locks: Dict[str, asyncio.Lock] = {}
        self._cleanup_running = False
        
    async def initialize(self):
        """Redis ì—°ê²° ì´ˆê¸°í™”"""
        await redis_client.connect()
        # Redis í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” í›„ self._partition_state_manager ìƒì„±
        from app.core.redis_client import PartitionStateManager
        self._partition_state_manager = PartitionStateManager(redis_client)
        logger.info("âœ… Redis partition manager initialized")
    
    async def shutdown(self):
        """Redis ì—°ê²° í•´ì œ"""
        await redis_client.disconnect()
        logger.info("âœ… Redis partition manager shutdown")
    
    def _get_partition_key(self, collection_name: str, partition_name: str) -> str:
        """íŒŒí‹°ì…˜ ê³ ìœ  í‚¤ ìƒì„±"""
        return f"{collection_name}/{partition_name}"
    
    def _get_lock(self, collection_name: str, partition_name: str) -> asyncio.Lock:
        """íŒŒí‹°ì…˜ë³„ Lock ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ìƒì„±)"""
        key = self._get_partition_key(collection_name, partition_name)
        if key not in self.partition_locks:
            self.partition_locks[key] = asyncio.Lock()
        return self.partition_locks[key]
    
    async def ensure_partition_loaded(
        self, 
        collection_name: str, 
        partition_name: str,
        force_reload: bool = False
    ) -> bool:
        """
        íŒŒí‹°ì…˜ì´ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ë¡œë“œ (ë™ì‹œ ë¡œë“œ ë°©ì§€)
        
        Args:
            collection_name: ì»¬ë ‰ì…˜ëª…
            partition_name: íŒŒí‹°ì…˜ëª…
            force_reload: ê°•ì œ ì¬ë¡œë“œ ì—¬ë¶€
        
        Returns:
            ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        key = self._get_partition_key(collection_name, partition_name)
        
        # Redisì—ì„œ ë¡œë“œ ìƒíƒœ í™•ì¸
        is_loaded = await self._partition_state_manager.is_partition_loaded(collection_name, partition_name)
        
        if not force_reload and is_loaded:
            # ì ‘ê·¼ ì‹œê°„ ì—…ë°ì´íŠ¸
            await self._partition_state_manager.update_access_time(collection_name, partition_name)
            logger.debug(f"âœ… Partition already loaded: {key}")
            return True
        
        # Lockì„ ì‚¬ìš©í•˜ì—¬ ë™ì‹œ ë¡œë“œ ë°©ì§€
        async with self._get_lock(collection_name, partition_name):
            # Lock ëŒ€ê¸° ì¤‘ ë‹¤ë¥¸ ìŠ¤ë ˆë“œê°€ ë¡œë“œí–ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¬í™•ì¸
            is_loaded = await self._partition_state_manager.is_partition_loaded(collection_name, partition_name)
            if not force_reload and is_loaded:
                await self._partition_state_manager.update_access_time(collection_name, partition_name)
                logger.debug(f"âœ… Partition loaded by another task: {key}")
                return True
            
            # íŒŒí‹°ì…˜ ë¡œë“œ ì‹œë„
            try:
                start_time = datetime.now()
                logger.info(f"ğŸ”„ Loading partition: {key}")
                
                collection = Collection(name=collection_name)
                partition = collection.partition(partition_name)
                
                # íŒŒí‹°ì…˜ ë¡œë“œ
                partition.load()
                
                # Redisì— ìƒíƒœ ì €ì¥
                await self._partition_state_manager.set_partition_loaded(collection_name, partition_name)
                
                elapsed = (datetime.now() - start_time).total_seconds()
                logger.info(f"âœ… Partition loaded successfully: {key} ({elapsed:.2f}s)")
                return True
                
            except Exception as e:
                logger.error(f"âŒ Failed to load partition {key}: {e}")
                return False
    
    async def unload_partition(self, collection_name: str, partition_name: str) -> bool:
        """
        íŒŒí‹°ì…˜ ì–¸ë¡œë“œ
        
        Args:
            collection_name: ì»¬ë ‰ì…˜ëª…
            partition_name: íŒŒí‹°ì…˜ëª…
        
        Returns:
            ì–¸ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        key = self._get_partition_key(collection_name, partition_name)
        
        try:
            logger.info(f"ğŸ”„ Unloading partition: {key}")
            
            collection = Collection(name=collection_name)
            partition = collection.partition(partition_name)
            
            # íŒŒí‹°ì…˜ ì–¸ë¡œë“œ
            partition.release()
            
            # Redisì—ì„œ ìƒíƒœ ì œê±°
            await self._partition_state_manager.set_partition_unloaded(collection_name, partition_name)
            
            logger.info(f"âœ… Partition unloaded successfully: {key}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Failed to unload partition {key}: {e}")
            return False
    
    async def reload_partitions_from_redis(self) -> Dict[str, Any]:
        """
        í”„ë¡œê·¸ë¨ ì‹œì‘ ì‹œ Redisì— ì €ì¥ëœ íŒŒí‹°ì…˜ë“¤ì„ ë‹¤ì‹œ ë¡œë“œ
        
        Returns:
            ë¡œë“œ ê²°ê³¼ í†µê³„
        """
        try:
            logger.info("ğŸ”„ Starting partition reload from Redis...")
            start_time = datetime.now()
            
            # Redisì—ì„œ í™œì„±í™”ëœ íŒŒí‹°ì…˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            all_partitions = await self._partition_state_manager.get_all_loaded_partitions()
            
            if not all_partitions:
                logger.info("ğŸ“¦ No partitions found in Redis - nothing to reload")
                return {
                    "partitions_found": 0,
                    "partitions_reloaded": 0,
                    "collections_loaded": 0,
                    "reload_time_seconds": 0
                }
            
            logger.info(f"ğŸ“¦ Found {len(all_partitions)} partitions in Redis to reload")
            
            # ì»¬ë ‰ì…˜ë³„ë¡œ íŒŒí‹°ì…˜ ê·¸ë£¹í™”
            partitions_by_collection: Dict[str, List[str]] = {}
            partition_access_data: Dict[str, Dict[str, Any]] = {}
            
            for partition_key, partition_data in all_partitions.items():
                collection_name = partition_data.get("collection")
                partition_name = partition_data.get("partition")
                
                if not collection_name or not partition_name:
                    logger.warning(f"âš ï¸ Invalid partition data: {partition_key}")
                    continue
                
                if collection_name not in partitions_by_collection:
                    partitions_by_collection[collection_name] = []
                partitions_by_collection[collection_name].append(partition_name)
                partition_access_data[f"{collection_name}/{partition_name}"] = partition_data
            
            logger.info(f"ğŸ“¦ Grouped into {len(partitions_by_collection)} collections")
            
            reloaded_count = 0
            collections_loaded_count = 0
            skipped_count = 0
            
            from pymilvus import utility, Collection
            
            # ì»¬ë ‰ì…˜ë³„ë¡œ ì²˜ë¦¬
            for collection_name, partition_names in partitions_by_collection.items():
                try:
                    logger.info(f"ğŸ” Processing collection: {collection_name} ({len(partition_names)} partitions)")
                    
                    collection = Collection(name=collection_name)
                    
                    # 1. ì»¬ë ‰ì…˜ ë¡œë“œ ìƒíƒœ í™•ì¸
                    try:
                        collection_load_state = utility.load_state(collection_name)
                        collection_is_loaded = (collection_load_state == utility.LoadState.Loaded)
                    except Exception:
                        collection_is_loaded = False
                    
                    if collection_is_loaded:
                        # 2. ì»¬ë ‰ì…˜ì´ ë¡œë“œë¨ â†’ ê° íŒŒí‹°ì…˜ ë¡œë“œ ìƒíƒœ í™•ì¸ ë° ë¡œë“œ
                        logger.info(f"   â†’ Collection is loaded, checking partitions individually")
                        for partition_name in partition_names:
                            try:
                                try:
                                    partition_load_state = utility.load_state(collection_name, partition_name)
                                    partition_is_loaded = (partition_load_state == utility.LoadState.Loaded)
                                except Exception:
                                    partition_is_loaded = False
                                
                                if not partition_is_loaded:
                                    # 3. íŒŒí‹°ì…˜ì´ ë¡œë“œ ì•ˆë˜ì–´ìˆë‹¤ë©´ ë¡œë“œ
                                    logger.info(f"   â†’ Partition {partition_name} not loaded, loading partition only")
                                    partition = collection.partition(partition_name)
                                    partition.load()
                                    reloaded_count += 1
                                    logger.info(f"   âœ… Partition reloaded: {partition_name}")
                                else:
                                    logger.info(f"   â†’ Partition {partition_name} already loaded, skipping")
                                    skipped_count += 1
                            except Exception as partition_error:
                                logger.error(f"   âŒ Failed to reload partition {collection_name}/{partition_name}: {partition_error}")
                                continue
                    else:
                        # 4. ì»¬ë ‰ì…˜ì´ ë¡œë“œ ì•ˆë˜ì–´ìˆë‹¤ë©´ collection.load(partition_names=[...])ìœ¼ë¡œ í•œ ë²ˆì— ë¡œë“œ
                        logger.info(f"   â†’ Collection not loaded, loading collection with {len(partition_names)} partitions")
                        collection.load(partition_names=partition_names)
                        collections_loaded_count += 1
                        reloaded_count += len(partition_names)
                        logger.info(f"   âœ… Collection loaded with {len(partition_names)} partitions")
                    
                    # ëª¨ë“  íŒŒí‹°ì…˜ ì ‘ê·¼ ì‹œê°„ ì—…ë°ì´íŠ¸ (ì»¬ë ‰ì…˜ ë¡œë“œ ì—¬ë¶€ì™€ ë¬´ê´€í•˜ê²Œ í•œ ë²ˆì—)
                    for partition_name in partition_names:
                        await self._partition_state_manager.update_access_time(collection_name, partition_name)
                    
                except Exception as collection_error:
                    logger.error(f"   âŒ Failed to process collection {collection_name}: {collection_error}")
                    continue
            
            elapsed_time = (datetime.now() - start_time).total_seconds()
            logger.info(f"âœ… Partition reload from Redis completed in {elapsed_time:.2f}s")
            logger.info(f"   - Partitions found: {len(all_partitions)}")
            logger.info(f"   - Partitions reloaded: {reloaded_count}")
            logger.info(f"   - Collections loaded: {collections_loaded_count}")
            logger.info(f"   - Partitions skipped (already loaded): {skipped_count}")
            
            return {
                "partitions_found": len(all_partitions),
                "partitions_reloaded": reloaded_count,
                "collections_loaded": collections_loaded_count,
                "partitions_skipped": skipped_count,
                "reload_time_seconds": elapsed_time
            }
            
        except Exception as e:
            logger.error(f"âŒ Failed to reload partitions from Redis: {e}")
            raise
    
    async def sync_partition_states(self, collection_names: List[str] = None) -> Dict[str, Any]:
        """
        Milvus íŒŒí‹°ì…˜ ìƒíƒœì™€ Redis ë™ê¸°í™”
        
        Args:
            collection_names: ë™ê¸°í™”í•  ì»¬ë ‰ì…˜ ëª©ë¡ (Noneì´ë©´ ëª¨ë“  ì»¬ë ‰ì…˜ ìë™ ì¡°íšŒ)
        
        Returns:
            ë™ê¸°í™” ê²°ê³¼ í†µê³„
        """
        try:
            logger.info("ğŸ”„ Starting Redis partition state synchronization...")
            redis_connected = await redis_client.is_connected()
            logger.info(f"ğŸ” Redis connection status: {redis_connected}")
            if not redis_connected:
                logger.error("âŒ Redis is not connected - cannot sync partition states")
                return {
                    "collections_checked": 0,
                    "partitions_synced": 0,
                    "sync_time_seconds": 0,
                    "error": "Redis not connected"
                }
            
            if not self._partition_state_manager:
                logger.error("âŒ Partition state manager is not initialized")
                return {
                    "collections_checked": 0,
                    "partitions_synced": 0,
                    "sync_time_seconds": 0,
                    "error": "Partition state manager not initialized"
                }
            start_time = datetime.now()
            
            if collection_names is None:
                # Milvusì—ì„œ ëª¨ë“  ì»¬ë ‰ì…˜ì„ ë™ì ìœ¼ë¡œ ì¡°íšŒ
                logger.info("ğŸ“‹ Discovering all collections in Milvus...")
                from pymilvus import utility
                all_collections = utility.list_collections()
                
                # ì‹œìŠ¤í…œ ì»¬ë ‰ì…˜ ì œì™¸
                collection_names = [name for name in all_collections if not name.startswith('_')]
                
                if not collection_names:
                    logger.info("â­ï¸  No collections found - skipping synchronization")
                    return {
                        "collections_checked": 0,
                        "partitions_synced": 0,
                        "sync_time_seconds": 0
                    }
            
            synced_count = 0
            collections_with_loaded_partitions = 0
            total_partitions_checked = 0
            
            logger.info(f"ğŸ“¦ Processing {len(collection_names)} collections...")
            
            for i, collection_name in enumerate(collection_names, 1):
                try:
                    logger.info(f"ğŸ” Checking collection: {collection_name}")
                    collection = Collection(name=collection_name)
                    
                    # ì»¬ë ‰ì…˜ì˜ ëª¨ë“  íŒŒí‹°ì…˜ ì¡°íšŒ
                    partitions = collection.partitions
                    partition_names = [p.name for p in partitions if p.name != "_default"]
                    logger.info(f"   ğŸ“‹ Found {len(partition_names)} partitions: {partition_names}")
                    
                    if not partition_names:
                        logger.info(f"   â­ï¸ No partitions found in {collection_name}")
                        continue
                    
                    # ì»¬ë ‰ì…˜ ë¡œë“œ ìƒíƒœ í™•ì¸ (ë‹¤ì–‘í•œ ë°©ë²• ì‹œë„)
                    collection_loaded = False
                    try:
                        # ë°©ë²• 1: has_collection ì‚¬ìš©
                        from pymilvus import utility
                        collection_loaded = utility.has_collection(collection_name)
                        logger.info(f"   ğŸ“Š Collection {collection_name} exists: {collection_loaded}")
                        
                        if collection_loaded:
                            # ë°©ë²• 2: ì»¬ë ‰ì…˜ ì†ì„± í™•ì¸
                            try:
                                # ì»¬ë ‰ì…˜ì´ ë¡œë“œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ë‹¤ë¥¸ ë°©ë²•ë“¤
                                collection.load()  # ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆìœ¼ë©´ ì—ëŸ¬ ì—†ì´ í†µê³¼
                                collection_loaded = True
                                logger.info(f"   ğŸ“Š Collection {collection_name} is already loaded")
                            except Exception as load_error:
                                logger.info(f"   ğŸ“Š Collection {collection_name} load check: {load_error}")
                                # ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆìœ¼ë©´ íŠ¹ì • ì—ëŸ¬ê°€ ë°œìƒí•  ìˆ˜ ìˆìŒ
                                if "already loaded" in str(load_error).lower():
                                    collection_loaded = True
                                    logger.info(f"   ğŸ“Š Collection {collection_name} is already loaded (detected from error)")
                                else:
                                    collection_loaded = False
                                    logger.info(f"   ğŸ“Š Collection {collection_name} is not loaded")
                        
                    except Exception as e:
                        logger.warning(f"   âš ï¸ Failed to check collection load status: {e}")
                        collection_loaded = False
                    
                    # ì»¬ë ‰ì…˜ì´ ë¡œë“œë˜ì–´ ìˆìœ¼ë©´ ëª¨ë“  íŒŒí‹°ì…˜ì„ ë¡œë“œëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
                    loaded_partitions = []
                    if collection_loaded:
                        loaded_partitions = partition_names.copy()
                        logger.info(f"   âœ… Collection is loaded - all partitions considered loaded: {loaded_partitions}")
                    else:
                        logger.info(f"   âŒ Collection is not loaded - no partitions loaded")
                    
                    total_partitions_checked += len(partition_names)
                    collection_loaded_count = 0
                    
                    for partition_name in partition_names:
                        try:
                            logger.info(f"   ğŸ” Checking partition: {collection_name}/{partition_name}")
                            
                            # ë¡œë“œëœ íŒŒí‹°ì…˜ ëª©ë¡ì—ì„œ í™•ì¸
                            is_loaded = partition_name in loaded_partitions
                            logger.info(f"      ğŸ“Š Partition {partition_name} loaded status: {is_loaded}")
                            
                            if is_loaded:
                                logger.info(f"      âœ… Partition {partition_name} is loaded - syncing to Redis")
                                # Redisì— ìƒíƒœ ì €ì¥ (ê°•ì œ ì—…ë°ì´íŠ¸)
                                await self._partition_state_manager.set_partition_loaded(collection_name, partition_name, force_update=True)
                                # ì ‘ê·¼ ì‹œê°„ì„ í˜„ì¬ ì‹œê°„ìœ¼ë¡œ ì„¤ì • (ì„œë²„ ì‹œì‘ ì‹œ ë™ê¸°í™”ëœ íŒŒí‹°ì…˜)
                                await self._partition_state_manager.update_access_time(collection_name, partition_name)
                                synced_count += 1
                                collection_loaded_count += 1
                            else:
                                logger.info(f"      âŒ Partition {partition_name} is not loaded")
                                
                        except Exception as partition_error:
                            logger.error(f"      âŒ Failed to check partition {collection_name}/{partition_name}: {partition_error}")
                            continue
                    
                    # ì»¬ë ‰ì…˜ë³„ ìš”ì•½ ë¡œê·¸
                    if collection_loaded_count > 0:
                        collections_with_loaded_partitions += 1
                        logger.info(f"   âœ… [{i:3d}/{len(collection_names)}] {collection_name}: {collection_loaded_count}/{len(partition_names)} partitions synced")
                    else:
                        logger.info(f"   âŒ [{i:3d}/{len(collection_names)}] {collection_name}: 0/{len(partition_names)} partitions synced")
                
                except Exception as collection_error:
                    logger.error(f"âŒ Failed to sync collection {collection_name}: {collection_error}")
                    continue
            
            elapsed_time = (datetime.now() - start_time).total_seconds()
            logger.info(f"âœ… Redis partition state sync completed in {elapsed_time:.2f}s")
            logger.info(f"   - Collections checked: {len(collection_names)}")
            logger.info(f"   - Collections with loaded partitions: {collections_with_loaded_partitions}")
            logger.info(f"   - Total partitions checked: {total_partitions_checked}")
            logger.info(f"   - Partitions synced: {synced_count}")
            
            return {
                "collections_checked": len(collection_names),
                "collections_with_loaded_partitions": collections_with_loaded_partitions,
                "total_partitions_checked": total_partitions_checked,
                "partitions_synced": synced_count,
                "sync_time_seconds": elapsed_time
            }
            
        except Exception as e:
            logger.error(f"âŒ Failed to sync partition states: {e}")
            raise
    
    async def auto_cleanup_loop(self):
        """
        ë°±ê·¸ë¼ìš´ë“œ: TTL ê¸°ë°˜ ìë™ ì •ë¦¬ ë£¨í”„
        - ì¼ì • ì‹œê°„ë§ˆë‹¤ ë¯¸ì‚¬ìš© íŒŒí‹°ì…˜ ì–¸ë¡œë“œ
        - ë©”ëª¨ë¦¬ ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ê°•ì œ ì •ë¦¬
        """
        self._cleanup_running = True
        logger.info(f"ğŸ”„ Redis auto cleanup loop started (interval: {settings.CLEANUP_INTERVAL_SECONDS}s, TTL: {settings.PARTITION_TTL_MINUTES}m)")
        
        try:
            while self._cleanup_running:
                await asyncio.sleep(settings.CLEANUP_INTERVAL_SECONDS)
                
                try:
                    # 1. TTL ê¸°ë°˜ ì •ë¦¬
                    await self._cleanup_by_ttl()
                    
                    # 2. ë©”ëª¨ë¦¬ ì„ê³„ê°’ ì²´í¬
                    await self._check_memory_and_cleanup()
                    
                except Exception as e:
                    logger.error(f"âŒ Cleanup error: {e}")
        
        finally:
            self._cleanup_running = False
            logger.info("ğŸ›‘ Redis auto cleanup loop stopped")
    
    async def _cleanup_by_ttl(self):
        """TTL ê¸°ë°˜ íŒŒí‹°ì…˜ ì–¸ë¡œë“œ"""
        try:
            # Redisì—ì„œ ë§Œë£Œëœ íŒŒí‹°ì…˜ ì¡°íšŒ
            expired_partitions = await self._partition_state_manager.get_expired_partitions(settings.PARTITION_TTL_MINUTES)
            
            # ë””ë²„ê¹…: í˜„ì¬ ìƒíƒœ ë¡œê·¸
            logger.info(f"ğŸ” Cleanup check: TTL={settings.PARTITION_TTL_MINUTES} minutes")
            logger.info(f"ğŸ” Found {len(expired_partitions)} expired partitions: {expired_partitions}")
            
            if not expired_partitions:
                logger.info("ğŸ” No expired partitions to cleanup")
                return
            
            logger.info(f"ğŸ—‘ï¸ TTL expired: unloading {len(expired_partitions)} partitions")
            
            # ë§Œë£Œëœ íŒŒí‹°ì…˜ë“¤ì„ ì¼ê´„ ì–¸ë¡œë“œ
            for partition_key in expired_partitions:
                try:
                    collection_name, partition_name = partition_key.split("/", 1)
                    await self.unload_partition(collection_name, partition_name)
                except Exception as e:
                    logger.error(f"âŒ Failed to unload {partition_key}: {e}")
            
            # Redisì—ì„œ ë§Œë£Œëœ íŒŒí‹°ì…˜ ì •ë¦¬
            await self._partition_state_manager.cleanup_expired_partitions(settings.PARTITION_TTL_MINUTES)
            
        except Exception as e:
            logger.error(f"âŒ TTL cleanup failed: {e}")
    
    async def _check_memory_and_cleanup(self):
        """ë©”ëª¨ë¦¬ ì„ê³„ê°’ ì²´í¬ ë° ê°•ì œ ì •ë¦¬"""
        try:
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            
            if memory_percent > settings.MEMORY_THRESHOLD_PERCENT:
                logger.warning(f"âš ï¸ Memory threshold exceeded: {memory_percent:.1f}% > {settings.MEMORY_THRESHOLD_PERCENT}%")
                
                # Redisì—ì„œ ëª¨ë“  ë¡œë“œëœ íŒŒí‹°ì…˜ ì¡°íšŒ
                all_partitions = await self._partition_state_manager.get_all_loaded_partitions()
                
                if not all_partitions:
                    logger.info("ğŸ” No partitions to unload for memory cleanup")
                    return
                
                # ì ‘ê·¼ ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬ (ì˜¤ë˜ëœ ê²ƒë¶€í„°)
                sorted_partitions = sorted(
                    all_partitions.items(),
                    key=lambda x: x[1].get("access_time", datetime.min)
                )
                
                # ìµœì†Œ 25% ì–¸ë¡œë“œ
                unload_count = max(1, len(sorted_partitions) // 4)
                logger.info(f"ğŸ—‘ï¸ Force unloading {unload_count} oldest partitions")
                
                for partition_key, _ in sorted_partitions[:unload_count]:
                    try:
                        collection_name, partition_name = partition_key.split("/", 1)
                        await self.unload_partition(collection_name, partition_name)
                        
                        # ë©”ëª¨ë¦¬ ì¬í™•ì¸
                        memory = psutil.virtual_memory()
                        if memory.percent < settings.MEMORY_THRESHOLD_PERCENT:
                            logger.info(f"âœ… Memory stabilized: {memory.percent:.1f}%")
                            break
                    except Exception as e:
                        logger.error(f"âŒ Failed to unload {partition_key}: {e}")
            
        except Exception as e:
            logger.error(f"âŒ Memory cleanup failed: {e}")
    
    async def stop_cleanup_loop(self):
        """Cleanup ë£¨í”„ ì¤‘ì§€"""
        self._cleanup_running = False
    
    async def get_status(self) -> Dict[str, Any]:
        """íŒŒí‹°ì…˜ ìƒíƒœ ì¡°íšŒ"""
        try:
            # Redisì—ì„œ ëª¨ë“  ë¡œë“œëœ íŒŒí‹°ì…˜ ì¡°íšŒ
            all_partitions = await self._partition_state_manager.get_all_loaded_partitions()
            
            # í†µê³„ ê³„ì‚°
            total_loaded = len(all_partitions)
            collections = set()
            oldest_partition = None
            oldest_time = None
            
            if all_partitions:
                for partition_key, data in all_partitions.items():
                    collection_name = data.get("collection", "")
                    collections.add(collection_name)
                    
                    access_time = data.get("access_time")
                    if access_time and (not oldest_time or access_time < oldest_time):
                        oldest_time = access_time
                        oldest_partition = partition_key
            
            return {
                "total_loaded_partitions": total_loaded,
                "collections_with_loaded_partitions": len(collections),
                "collections": list(collections),
                "oldest_partition": {
                    "key": oldest_partition,
                    "access_time": oldest_time.isoformat() if oldest_time else None,
                    "minutes_ago": int((datetime.now() - oldest_time).total_seconds() / 60) if oldest_time else None
                } if oldest_partition else None,
                "loaded_partitions": all_partitions,
                "config": {
                    "ttl_minutes": settings.PARTITION_TTL_MINUTES,
                    "cleanup_interval_seconds": settings.CLEANUP_INTERVAL_SECONDS,
                    "memory_threshold_percent": settings.MEMORY_THRESHOLD_PERCENT
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ Failed to get status: {e}")
            return {
                "error": str(e),
                "total_loaded_partitions": 0,
                "collections_with_loaded_partitions": 0
            }
    
    async def update_partition_access_time(self, collection_name: str, partition_name: str):
        """íŒŒí‹°ì…˜ ì ‘ê·¼ ì‹œê°„ ì—…ë°ì´íŠ¸ (TTL ì •ë¦¬ìš©)"""
        await self._partition_state_manager.update_access_time(collection_name, partition_name)


# ì „ì—­ Redis ê¸°ë°˜ íŒŒí‹°ì…˜ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
redis_partition_manager = RedisMilvusPartitionManager()
