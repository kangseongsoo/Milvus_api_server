"""
ë°ì´í„° ê´€ë¦¬ API (CRUD)
"""
from fastapi import APIRouter, HTTPException, status, Query
from app.models.document import (
    DocumentInsertRequest,
    DocumentInsertResponse,
    BatchInsertRequest,
    BatchInsertResponse,
    BatchInsertWithEmbeddingsRequest,
    DocumentResponse,
    DocumentUpdateRequest,
    DocumentUpdateResponse,
    DocumentDeleteRequest,
    DocumentDeleteResponse,
    BotDeleteRequest,
    BotDeleteResponse,
    MetadataUpdateRequest,
    MetadataUpdateResponse
)
from app.schemas.milvus_metadata import filter_milvus_metadata
from app.utils.logger import setup_logger
from app.core.auto_flusher import auto_flusher
from app.core.postgres_client import postgres_client
from app.core.milvus_client import milvus_client
from app.core.embedding import embedding_service
from app.config import settings
from pymilvus import Collection
from datetime import datetime

logger = setup_logger(__name__)
router = APIRouter()


def generate_partition_name(chat_bot_id: str) -> str:
    """chat_bot_idë¡œ íŒŒí‹°ì…˜ëª… ìë™ ìƒì„±"""
    return f"bot_{chat_bot_id.replace('-', '')}"


@router.post("/insert", response_model=DocumentInsertResponse, status_code=status.HTTP_201_CREATED)
async def insert_document(request: DocumentInsertRequest):
    """
    ë¬¸ì„œ ë°ì´í„° ì‚½ì… (ê°œì„ ëœ Saga Pattern)
    
    ì „ì²˜ë¦¬ ì„œë²„ë¡œë¶€í„° ê³„ì •ëª… + ë©”íƒ€ë°ì´í„° + í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ë°›ì•„
    1. PostgreSQL íŠ¸ëœì­ì…˜ìœ¼ë¡œ ë¬¸ì„œ+ì²­í¬ ì›ìì„± ë³´ì¥
    2. ì„ë² ë”© ìƒì„± (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
    3. Milvus ë²¡í„° ì €ì¥ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
    4. ì‹¤íŒ¨ ì‹œ ë³´ìƒ íŠ¸ëœì­ì…˜ìœ¼ë¡œ PostgreSQL ë¡¤ë°±
    """
    doc_id = None
    try:
        start_time = datetime.now()
        collection_name = f"collection_{request.account_name}"
        partition_name = generate_partition_name(request.chat_bot_id)
        
        logger.info(f"ğŸ“ ë¬¸ì„œ ì‚½ì… ì‹œì‘ (Saga Pattern)")
        logger.info(f"   - Account: {request.account_name}")
        logger.info(f"   - Bot ID: {request.chat_bot_id}")
        logger.info(f"   - Title: {request.metadata.get('title', '(ì œëª© ì—†ìŒ)')}")
        logger.info(f"   - Chunks: {len(request.chunks)}")
        logger.info(f"   - Collection: {collection_name}")
        logger.info(f"   - Partition: {partition_name}")
        
        # ========== Step 1: ë©”íƒ€ë°ì´í„° ë¶„ë¦¬ ==========
        all_metadata = request.metadata or {}
        milvus_metadata = filter_milvus_metadata(all_metadata)  # Milvus í•„í„°ë§ìš©ë§Œ ì¶”ì¶œ
        
        logger.info(f"ğŸ“Š ë©”íƒ€ë°ì´í„° ë¶„ë¦¬ ì™„ë£Œ:")
        logger.info(f"   - Milvus í•„í„°ë§ìš©: {len(milvus_metadata)}ê°œ í•„ë“œ")
        logger.info(f"   - PostgreSQL ì „ì²´: {len(all_metadata)}ê°œ í•„ë“œ (ì „ì²´ ì €ì¥)")
        
        # ========== Step 2: PostgreSQL íŠ¸ëœì­ì…˜ (ì›ìì„± ë³´ì¥) ==========
        postgres_start = datetime.now()
        
        doc_id = await postgres_client.insert_document_with_chunks_transaction(
            account_name=request.account_name,
            document_data={
                "chat_bot_id": request.chat_bot_id,
                "content_name": request.content_name,  # ë¬¸ì„œ ê³ ìœ  ì‹ë³„ì
                "metadata": all_metadata  # ì „ì²´ ë©”íƒ€ë°ì´í„°ë¥¼ PostgreSQLì— ì €ì¥
            },
            chunks=[{"chunk_index": c.chunk_index, "text": c.text} for c in request.chunks]
        )
        
        postgres_time = (datetime.now() - postgres_start).total_seconds() * 1000
        logger.info(f"âœ… PostgreSQL íŠ¸ëœì­ì…˜ ì™„ë£Œ: doc_id={doc_id}")
        
        # ========== Step 2: ì„ë² ë”© ìƒì„± (ì¬ì‹œë„ ë¡œì§) ==========
        embedding_start = datetime.now()
        
        try:
            embeddings = await embedding_service.batch_embed_with_retry(
                texts=[chunk.text for chunk in request.chunks],
                max_retries=3,
                backoff=2.0
            )
            embedding_time = (datetime.now() - embedding_start).total_seconds() * 1000
            logger.info(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ: {len(embeddings)}ê°œ ë²¡í„°")
            
        except Exception as embedding_error:
            # ì„ë² ë”© ì‹¤íŒ¨ ì‹œ PostgreSQL ë¡¤ë°±
            logger.error(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨, PostgreSQL ë¡¤ë°± ì‹œì‘: {str(embedding_error)}")
            await postgres_client.delete_document(request.account_name, request.chat_bot_id, doc_id)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {str(embedding_error)}"
            )
        
        # ========== Step 3: Milvus ë²¡í„° ì €ì¥ (ì¬ì‹œë„ ë¡œì§) ==========
        milvus_start = datetime.now()
        
        try:
            await milvus_client.insert_vectors_with_retry(
                account_name=request.account_name,
                chat_bot_id=request.chat_bot_id,
                partition_name=partition_name,
                doc_id=doc_id,
                content_name=request.content_name,  # content_name ì¶”ê°€
                chunks=[
                    {
                        "chunk_index": chunk.chunk_index,
                        "embedding": embeddings[idx],
                        "text": chunk.text
                    }
                    for idx, chunk in enumerate(request.chunks)
                ],
                metadata=milvus_metadata,  # í•„í„°ë§ìš© ë©”íƒ€ë°ì´í„°ë§Œ Milvusì—
                max_retries=3,
                backoff=2.0
            )
            milvus_time = (datetime.now() - milvus_start).total_seconds() * 1000
            logger.info(f"âœ… Milvus ë²¡í„° ì‚½ì… ì™„ë£Œ")
            
        except Exception as milvus_error:
            # Milvus ì‹¤íŒ¨ ì‹œ PostgreSQL ë¡¤ë°± (ë³´ìƒ íŠ¸ëœì­ì…˜)
            logger.error(f"âŒ Milvus ì‚½ì… ì‹¤íŒ¨, PostgreSQL ë¡¤ë°± ì‹œì‘: {str(milvus_error)}")
            await postgres_client.delete_document(request.account_name, request.chat_bot_id, doc_id)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Milvus ì‚½ì… ì‹¤íŒ¨: {str(milvus_error)}"
            )
        
        # ========== Step 4: ğŸ”¥ ìë™ flush ë§ˆí‚¹ (ì´ë²¤íŠ¸ ê¸°ë°˜) ==========
        await auto_flusher.mark_for_flush(collection_name)
        logger.info(f"ğŸ”¥ Flush marked: {collection_name} (will flush within 0.5s)")
        
        total_time = (datetime.now() - start_time).total_seconds() * 1000
        
        logger.info(f"âœ… ë¬¸ì„œ ì‚½ì… ì™„ë£Œ (Saga Pattern ì„±ê³µ)")
        logger.info(f"   - doc_id: {doc_id}")
        logger.info(f"   - ì²­í¬ ìˆ˜: {len(request.chunks)}")
        logger.info(f"   - ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ms")
        logger.info(f"   - ê²€ìƒ‰ ê°€ëŠ¥ ì‹œê°„: 0.5ì´ˆ ì´ë‚´")
        
        return DocumentInsertResponse(
            status="success",
            doc_id=doc_id,
            total_chunks=len(request.chunks),
            postgres_insert_time_ms=postgres_time,
            embedding_time_ms=embedding_time,
            milvus_insert_time_ms=milvus_time,
            total_time_ms=total_time,
            searchable_within_seconds=0.5
        )
        
    except HTTPException:
        # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì¬ë°œìƒ
        raise
    except Exception as e:
        # ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ì‹œ PostgreSQL ë¡¤ë°±
        if doc_id is not None:
            logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ, PostgreSQL ë¡¤ë°± ì‹œì‘: {str(e)}")
            try:
                await postgres_client.delete_document(request.account_name, request.chat_bot_id, doc_id)
                logger.info(f"âœ… PostgreSQL ë¡¤ë°± ì™„ë£Œ: doc_id={doc_id}")
            except Exception as rollback_error:
                logger.error(f"âŒ PostgreSQL ë¡¤ë°± ì‹¤íŒ¨: {str(rollback_error)}")
        
        logger.error(f"âŒ ë¬¸ì„œ ì‚½ì… ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to insert document: {str(e)}"
        )


@router.post("/insert/batch", response_model=BatchInsertResponse, status_code=status.HTTP_201_CREATED)
async def batch_insert_documents(request: BatchInsertRequest):
    """
    ì—¬ëŸ¬ ë¬¸ì„œ ì¼ê´„ ì‚½ì… (ê°œì„ ëœ Saga Pattern)
    
    ì „ì²˜ë¦¬ ì„œë²„ì—ì„œ ì—¬ëŸ¬ ë¬¸ì„œë¥¼ í•œ ë²ˆì— ì „ì†¡
    1. PostgreSQL íŠ¸ëœì­ì…˜ìœ¼ë¡œ ëª¨ë“  ë¬¸ì„œ+ì²­í¬ ì›ìì„± ë³´ì¥
    2. ë°°ì¹˜ ì„ë² ë”© ìƒì„± (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
    3. Milvus ë°°ì¹˜ ë²¡í„° ì €ì¥ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
    4. ì‹¤íŒ¨ ì‹œ ë³´ìƒ íŠ¸ëœì­ì…˜ìœ¼ë¡œ PostgreSQL ë¡¤ë°±
    """
    doc_ids = []
    try:
        start_time = datetime.now()
        total_docs = len(request.documents)
        total_chunks = sum(len(doc.chunks) for doc in request.documents)
        collection_name = f"collection_{request.account_name}"
        
        logger.info(f"ğŸ“ ë°°ì¹˜ ì‚½ì… ì‹œì‘ (Saga Pattern)")
        logger.info(f"   - Account: {request.account_name}")
        logger.info(f"   - Documents: {total_docs}ê°œ")
        logger.info(f"   - Total Chunks: {total_chunks}ê°œ")
        logger.info(f"   - Collection: {collection_name}")
        
        # ========== Step 1: PostgreSQL ë°°ì¹˜ íŠ¸ëœì­ì…˜ (ì›ìì„± ë³´ì¥) ==========
        postgres_start = datetime.now()
        
        # ë¬¸ì„œ ë°ì´í„° ì¤€ë¹„ (ë©”íƒ€ë°ì´í„° ë¶„ë¦¬)
        documents_data = []
        for doc in request.documents:
            # ë©”íƒ€ë°ì´í„° ë¶„ë¦¬
            all_metadata = doc.metadata or {}
            
            documents_data.append({
                "document_data": {
                    "chat_bot_id": doc.chat_bot_id,
                    "content_name": doc.content_name,  # ë¬¸ì„œ ê³ ìœ  ì‹ë³„ì
                    "metadata": all_metadata  # ì „ì²´ ë©”íƒ€ë°ì´í„°ë¥¼ PostgreSQLì— ì €ì¥
                },
                "chunks": [{"chunk_index": c.chunk_index, "text": c.text} for c in doc.chunks]
            })
        
        doc_ids = await postgres_client.batch_insert_documents_with_chunks_transaction(
            account_name=request.account_name,
            documents=documents_data
        )
        
        postgres_time = (datetime.now() - postgres_start).total_seconds() * 1000
        logger.info(f"âœ… PostgreSQL ë°°ì¹˜ íŠ¸ëœì­ì…˜ ì™„ë£Œ: {len(doc_ids)}ê°œ ë¬¸ì„œ")
        
        # ========== Step 2: ë°°ì¹˜ ì„ë² ë”© ìƒì„± (ì¬ì‹œë„ ë¡œì§) ==========
        embedding_start = datetime.now()
        
        try:
            # ëª¨ë“  ì²­í¬ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
            all_chunk_texts = []
            for doc in request.documents:
                all_chunk_texts.extend([chunk.text for chunk in doc.chunks])
            
            # ë°°ì¹˜ ì„ë² ë”© ìƒì„±
            all_embeddings = await embedding_service.batch_embed_with_retry(
                texts=all_chunk_texts,
                max_retries=3,
                backoff=2.0
            )
            
            embedding_time = (datetime.now() - embedding_start).total_seconds() * 1000
            logger.info(f"âœ… ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì™„ë£Œ: {len(all_embeddings)}ê°œ ë²¡í„°")
            
        except Exception as embedding_error:
            # ì„ë² ë”© ì‹¤íŒ¨ ì‹œ PostgreSQL ë¡¤ë°±
            logger.error(f"âŒ ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨, PostgreSQL ë¡¤ë°± ì‹œì‘: {str(embedding_error)}")
            for doc_id in doc_ids:
                try:
                    await postgres_client.delete_document(request.account_name, request.documents[0].chat_bot_id, doc_id)
                except:
                    pass  # ë¡¤ë°± ì‹¤íŒ¨ëŠ” ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ê³„ì†
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {str(embedding_error)}"
            )
        
        # ========== Step 3: Milvus ë°°ì¹˜ ë²¡í„° ì €ì¥ (ì¬ì‹œë„ ë¡œì§) ==========
        milvus_start = datetime.now()
        
        try:
            # ë¬¸ì„œë³„ ë°ì´í„° ì¤€ë¹„
            documents_data = []
            embedding_idx = 0
            
            for i, doc in enumerate(request.documents):
                doc_id = doc_ids[i]
                
                # ë©”íƒ€ë°ì´í„° ë¶„ë¦¬
                all_metadata = doc.metadata or {}
                milvus_metadata = filter_milvus_metadata(all_metadata)  # Milvus í•„í„°ë§ìš©
                
                chunks_with_embeddings = []
                for chunk in doc.chunks:
                    chunks_with_embeddings.append({
                        "chunk_index": chunk.chunk_index,
                        "embedding": all_embeddings[embedding_idx],
                        "text": chunk.text
                    })
                    embedding_idx += 1
                
                documents_data.append({
                    "chat_bot_id": doc.chat_bot_id,
                    "doc_id": doc_id,
                    "content_name": doc.content_name,  # content_name ì¶”ê°€
                    "chunks": chunks_with_embeddings,
                    "metadata": milvus_metadata  # í•„í„°ë§ìš© ë©”íƒ€ë°ì´í„°ë§Œ Milvusì—
                })
            
            # Milvus ë°°ì¹˜ ì‚½ì…
            await milvus_client.batch_insert_vectors_with_retry(
                account_name=request.account_name,
                documents_data=documents_data,
                metadata={},  # ê°œë³„ ë¬¸ì„œ ë©”íƒ€ë°ì´í„°ê°€ ìš°ì„ ë¨
                max_retries=3,
                backoff=2.0
            )
            
            milvus_time = (datetime.now() - milvus_start).total_seconds() * 1000
            logger.info(f"âœ… Milvus ë°°ì¹˜ ë²¡í„° ì‚½ì… ì™„ë£Œ")
            
        except Exception as milvus_error:
            # Milvus ì‹¤íŒ¨ ì‹œ PostgreSQL ë¡¤ë°± (ë³´ìƒ íŠ¸ëœì­ì…˜)
            logger.error(f"âŒ Milvus ë°°ì¹˜ ì‚½ì… ì‹¤íŒ¨, PostgreSQL ë¡¤ë°± ì‹œì‘: {str(milvus_error)}")
            for doc_id in doc_ids:
                try:
                    await postgres_client.delete_document(request.account_name, request.documents[0].chat_bot_id, doc_id)
                except:
                    pass  # ë¡¤ë°± ì‹¤íŒ¨ëŠ” ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ê³„ì†
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Milvus ë°°ì¹˜ ì‚½ì… ì‹¤íŒ¨: {str(milvus_error)}"
            )
        
        # ========== Step 4: ğŸ”¥ ìë™ flush ë§ˆí‚¹ (ì´ë²¤íŠ¸ ê¸°ë°˜) ==========
        await auto_flusher.mark_for_flush(collection_name)
        logger.info(f"ğŸ”¥ Flush marked: {collection_name}")
        
        total_time = (datetime.now() - start_time).total_seconds() * 1000
        
        # ì„±ê³µ ê²°ê³¼ ìƒì„±
        results = []
        for i, doc in enumerate(request.documents):
            results.append({
                "doc_id": doc_ids[i],
                "title": doc.metadata.get('title', '(ì œëª© ì—†ìŒ)') if doc.metadata else '(ì œëª© ì—†ìŒ)',
                "total_chunks": len(doc.chunks),
                "success": True
            })
        
        logger.info(f"âœ… ë°°ì¹˜ ì‚½ì… ì™„ë£Œ (Saga Pattern ì„±ê³µ)")
        logger.info(f"   - ì„±ê³µ: {len(doc_ids)}ê°œ ë¬¸ì„œ")
        logger.info(f"   - ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ms")
        logger.info(f"   - ê²€ìƒ‰ ê°€ëŠ¥ ì‹œê°„: 0.5ì´ˆ ì´ë‚´")
        
        from app.models.document import BatchInsertResult
        return BatchInsertResponse(
            status="success",
            total_documents=total_docs,
            total_chunks=total_chunks,
            success_count=len(doc_ids),
            failure_count=0,
            results=[BatchInsertResult(**r) for r in results],
            postgres_insert_time_ms=postgres_time,
            embedding_time_ms=embedding_time,
            milvus_insert_time_ms=milvus_time,
            total_time_ms=total_time
        )
        
    except HTTPException:
        # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì¬ë°œìƒ
        raise
    except Exception as e:
        # ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ì‹œ PostgreSQL ë¡¤ë°±
        if doc_ids:
            logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ, PostgreSQL ë¡¤ë°± ì‹œì‘: {str(e)}")
            for doc_id in doc_ids:
                try:
                    await postgres_client.delete_document(request.account_name, request.documents[0].chat_bot_id, doc_id)
                except Exception as rollback_error:
                    logger.error(f"âŒ PostgreSQL ë¡¤ë°± ì‹¤íŒ¨ (doc_id: {doc_id}): {str(rollback_error)}")
        
        logger.error(f"âŒ ë°°ì¹˜ ì‚½ì… ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Batch insert failed: {str(e)}"
        )


@router.post("/insert/batch/with-embeddings", response_model=BatchInsertResponse, status_code=status.HTTP_201_CREATED)
async def batch_insert_documents_with_embeddings(request: BatchInsertWithEmbeddingsRequest):
    """
    ì„ë² ë”©ì„ í¬í•¨í•œ ì—¬ëŸ¬ ë¬¸ì„œ ì¼ê´„ ì‚½ì… (ë§ˆì´ê·¸ë ˆì´ì…˜ìš©)
    
    ê¸°ì¡´ PostgreSQLì— ì €ì¥ëœ ì„ë² ë”© ë²¡í„°ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì—¬ Milvusì— ì‚½ì…
    - ì„ë² ë”© ìƒì„± ë‹¨ê³„ë¥¼ ìŠ¤í‚µí•˜ê³  ì œê³µëœ ë²¡í„°ë¥¼ ì§ì ‘ ì‚¬ìš©
    - PostgreSQL íŠ¸ëœì­ì…˜ìœ¼ë¡œ ëª¨ë“  ë¬¸ì„œ+ì²­í¬ ì›ìì„± ë³´ì¥
    - Milvus ë°°ì¹˜ ë²¡í„° ì €ì¥ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
    - ì‹¤íŒ¨ ì‹œ ë³´ìƒ íŠ¸ëœì­ì…˜ìœ¼ë¡œ PostgreSQL ë¡¤ë°±
    """
    doc_ids = []
    try:
        start_time = datetime.now()
        total_docs = len(request.documents)
        total_chunks = sum(len(doc.chunks) for doc in request.documents)
        collection_name = f"collection_{request.account_name}"
        
        logger.info(f"ğŸ“ ë°°ì¹˜ ì‚½ì… ì‹œì‘ (ì„ë² ë”© í¬í•¨, ë§ˆì´ê·¸ë ˆì´ì…˜ìš©)")
        logger.info(f"   - Account: {request.account_name}")
        logger.info(f"   - Documents: {total_docs}ê°œ")
        logger.info(f"   - Total Chunks: {total_chunks}ê°œ")
        logger.info(f"   - Collection: {collection_name}")
        logger.info(f"   - ì„ë² ë”© ìƒì„±: ìŠ¤í‚µ (ê¸°ì¡´ ë²¡í„° ì‚¬ìš©)")
        
        # ========== Step 1: PostgreSQL ë°°ì¹˜ íŠ¸ëœì­ì…˜ (ì›ìì„± ë³´ì¥) ==========
        postgres_start = datetime.now()
        
        # ë¬¸ì„œ ë°ì´í„° ì¤€ë¹„ (ë©”íƒ€ë°ì´í„° ë¶„ë¦¬)
        documents_data = []
        for doc in request.documents:
            # ë©”íƒ€ë°ì´í„° ë¶„ë¦¬
            all_metadata = doc.metadata or {}
            
            documents_data.append({
                "document_data": {
                    "chat_bot_id": doc.chat_bot_id,
                    "content_name": doc.content_name,  # ë¬¸ì„œ ê³ ìœ  ì‹ë³„ì
                    "metadata": all_metadata  # ì „ì²´ ë©”íƒ€ë°ì´í„°ë¥¼ PostgreSQLì— ì €ì¥
                },
                "chunks": [{"chunk_index": c.chunk_index, "text": c.text} for c in doc.chunks]
            })
        
        doc_ids = await postgres_client.batch_insert_documents_with_chunks_transaction(
            account_name=request.account_name,
            documents=documents_data
        )
        
        postgres_time = (datetime.now() - postgres_start).total_seconds() * 1000
        logger.info(f"âœ… PostgreSQL ë°°ì¹˜ íŠ¸ëœì­ì…˜ ì™„ë£Œ: {len(doc_ids)}ê°œ ë¬¸ì„œ")
        
        # ========== Step 2: ì„ë² ë”© ìƒì„± ìŠ¤í‚µ (ì´ë¯¸ ì œê³µë¨) ==========
        embedding_start = datetime.now()
        embedding_time = 0.0  # ì„ë² ë”© ìƒì„±í•˜ì§€ ì•ŠìŒ
        logger.info(f"â­ï¸ ì„ë² ë”© ìƒì„± ìŠ¤í‚µ (ê¸°ì¡´ ë²¡í„° ì‚¬ìš©): {total_chunks}ê°œ ë²¡í„°")
        
        # ========== Step 3: Milvus ë°°ì¹˜ ë²¡í„° ì €ì¥ (ì¬ì‹œë„ ë¡œì§) ==========
        milvus_start = datetime.now()
        
        try:
            # ë¬¸ì„œë³„ ë°ì´í„° ì¤€ë¹„
            documents_data = []
            
            for i, doc in enumerate(request.documents):
                doc_id = doc_ids[i]
                
                # ë©”íƒ€ë°ì´í„° ë¶„ë¦¬
                all_metadata = doc.metadata or {}
                milvus_metadata = filter_milvus_metadata(all_metadata)  # Milvus í•„í„°ë§ìš©
                
                # ì²­í¬ì— ì´ë¯¸ ì„ë² ë”©ì´ í¬í•¨ë˜ì–´ ìˆìŒ
                chunks_with_embeddings = []
                for chunk in doc.chunks:
                    chunks_with_embeddings.append({
                        "chunk_index": chunk.chunk_index,
                        "embedding": chunk.embedding,  # ì œê³µëœ ì„ë² ë”© ì‚¬ìš©
                        "text": chunk.text
                    })
                
                documents_data.append({
                    "chat_bot_id": doc.chat_bot_id,
                    "doc_id": doc_id,
                    "content_name": doc.content_name,  # content_name ì¶”ê°€
                    "chunks": chunks_with_embeddings,
                    "metadata": milvus_metadata  # í•„í„°ë§ìš© ë©”íƒ€ë°ì´í„°ë§Œ Milvusì—
                })
            
            # Milvus ë°°ì¹˜ ì‚½ì…
            await milvus_client.batch_insert_vectors_with_retry(
                account_name=request.account_name,
                documents_data=documents_data,
                metadata={},  # ê°œë³„ ë¬¸ì„œ ë©”íƒ€ë°ì´í„°ê°€ ìš°ì„ ë¨
                max_retries=3,
                backoff=2.0
            )
            
            milvus_time = (datetime.now() - milvus_start).total_seconds() * 1000
            logger.info(f"âœ… Milvus ë°°ì¹˜ ë²¡í„° ì‚½ì… ì™„ë£Œ")
            
        except Exception as milvus_error:
            # Milvus ì‹¤íŒ¨ ì‹œ PostgreSQL ë¡¤ë°± (ë³´ìƒ íŠ¸ëœì­ì…˜)
            logger.error(f"âŒ Milvus ë°°ì¹˜ ì‚½ì… ì‹¤íŒ¨, PostgreSQL ë¡¤ë°± ì‹œì‘: {str(milvus_error)}")
            for doc_id in doc_ids:
                try:
                    await postgres_client.delete_document(request.account_name, request.documents[0].chat_bot_id, doc_id)
                except:
                    pass  # ë¡¤ë°± ì‹¤íŒ¨ëŠ” ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ê³„ì†
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Milvus ë°°ì¹˜ ì‚½ì… ì‹¤íŒ¨: {str(milvus_error)}"
            )
        
        # ========== Step 4: ğŸ”¥ ìë™ flush ë§ˆí‚¹ (ì´ë²¤íŠ¸ ê¸°ë°˜) ==========
        await auto_flusher.mark_for_flush(collection_name)
        logger.info(f"ğŸ”¥ Flush marked: {collection_name}")
        
        total_time = (datetime.now() - start_time).total_seconds() * 1000
        
        # ì„±ê³µ ê²°ê³¼ ìƒì„±
        results = []
        for i, doc in enumerate(request.documents):
            results.append({
                "doc_id": doc_ids[i],
                "title": doc.metadata.get('title', '(ì œëª© ì—†ìŒ)') if doc.metadata else '(ì œëª© ì—†ìŒ)',
                "total_chunks": len(doc.chunks),
                "success": True
            })
        
        logger.info(f"âœ… ë°°ì¹˜ ì‚½ì… ì™„ë£Œ (ì„ë² ë”© í¬í•¨, ë§ˆì´ê·¸ë ˆì´ì…˜)")
        logger.info(f"   - ì„±ê³µ: {len(doc_ids)}ê°œ ë¬¸ì„œ")
        logger.info(f"   - ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ms")
        logger.info(f"   - ì„ë² ë”© ìƒì„± ì‹œê°„: 0ms (ìŠ¤í‚µë¨)")
        logger.info(f"   - ê²€ìƒ‰ ê°€ëŠ¥ ì‹œê°„: 0.5ì´ˆ ì´ë‚´")
        
        from app.models.document import BatchInsertResult
        return BatchInsertResponse(
            status="success",
            total_documents=total_docs,
            total_chunks=total_chunks,
            success_count=len(doc_ids),
            failure_count=0,
            results=[BatchInsertResult(**r) for r in results],
            postgres_insert_time_ms=postgres_time,
            embedding_time_ms=embedding_time,  # 0ms
            milvus_insert_time_ms=milvus_time,
            total_time_ms=total_time
        )
        
    except HTTPException:
        # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì¬ë°œìƒ
        raise
    except Exception as e:
        # ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ì‹œ PostgreSQL ë¡¤ë°±
        if doc_ids:
            logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ, PostgreSQL ë¡¤ë°± ì‹œì‘: {str(e)}")
            for doc_id in doc_ids:
                try:
                    await postgres_client.delete_document(request.account_name, request.documents[0].chat_bot_id, doc_id)
                except Exception as rollback_error:
                    logger.error(f"âŒ PostgreSQL ë¡¤ë°± ì‹¤íŒ¨ (doc_id: {doc_id}): {str(rollback_error)}")
        
        logger.error(f"âŒ ë°°ì¹˜ ì‚½ì… ì‹¤íŒ¨ (ì„ë² ë”© í¬í•¨): {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Batch insert with embeddings failed: {str(e)}"
        )


@router.get("/document/{doc_id}", response_model=DocumentResponse)
async def get_document(
    doc_id: int,
    account_name: str = Query(..., description="ê³„ì •ëª…"),
    chat_bot_id: str = Query(..., description="ì±—ë´‡ ID (UUID)")
):
    """
    ë¬¸ì„œ ì¡°íšŒ (doc_id ê¸°ë°˜)
    
    í•´ë‹¹ ê³„ì • ë° ë´‡ì˜ íŒŒí‹°ì…˜ì—ì„œ ë¬¸ì„œì™€ ëª¨ë“  ì²­í¬ ì¡°íšŒ
    """
    try:
        logger.info(f"ë¬¸ì„œ ì¡°íšŒ ìš”ì²­ (account: {account_name}, bot: {chat_bot_id}): doc_id={doc_id}")
        
        # TODO: PostgreSQLì—ì„œ ë¬¸ì„œ ì¡°íšŒ (ìë™ìœ¼ë¡œ í•´ë‹¹ íŒŒí‹°ì…˜ë§Œ ìŠ¤ìº”)
        # document = await postgres_client.get_document(account_name, chat_bot_id, doc_id)
        # chunks = await postgres_client.get_chunks(account_name, chat_bot_id, doc_id)
        
        raise HTTPException(
            status_code=status.HTTP_501_NOT_IMPLEMENTED,
            detail="êµ¬í˜„ ì˜ˆì •"
        )
    except Exception as e:
        logger.error(f"ë¬¸ì„œ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to retrieve document: {str(e)}"
        )


@router.put("/document/{doc_id}", response_model=DocumentUpdateResponse)
async def update_document(doc_id: int, request: DocumentUpdateRequest):
    """
    ë¬¸ì„œ ì „ì²´ ì—…ë°ì´íŠ¸
    
    ê¸°ì¡´ ë¬¸ì„œì˜ ëª¨ë“  ì²­í¬ë¥¼ ì‚­ì œí•˜ê³  ìƒˆë¡œìš´ ë°ì´í„°ë¡œ êµì²´
    """
    try:
        logger.info(f"ë¬¸ì„œ ì—…ë°ì´íŠ¸ ìš”ì²­ (account: {request.account_name}, bot: {request.chat_bot_id}): doc_id={doc_id}")
        
        # TODO: íŠ¸ëœì­ì…˜ ì²˜ë¦¬
        # async with transaction():
        #     chunk_count = len(request.chunks)
        #     document_data = {
        #         "chat_bot_id": request.chat_bot_id,
        #         "metadata": request.metadata or {}  # ëª¨ë“  ë©”íƒ€ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ì €ì¥
        #     }
        #     await postgres_client.update_document(request.account_name, request.chat_bot_id, doc_id, document_data, chunk_count)  # â­ ì²­í¬ ìˆ˜ ì „ë‹¬
        #     deleted_count = await postgres_client.delete_chunks(request.account_name, request.chat_bot_id, doc_id)
        #     await postgres_client.insert_chunks(request.account_name, request.chat_bot_id, doc_id, [c.dict() for c in request.chunks])
        #     await milvus_client.delete_by_doc_id(doc_id)
        #     embeddings = await embedding_service.batch_embed([chunk.text for chunk in request.chunks])
        #     await milvus_client.insert(doc_id, embeddings)
        
        raise HTTPException(
            status_code=status.HTTP_501_NOT_IMPLEMENTED,
            detail="êµ¬í˜„ ì˜ˆì •"
        )
    except Exception as e:
        logger.error(f"ë¬¸ì„œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to update document: {str(e)}"
        )


@router.post("/document/delete", response_model=DocumentDeleteResponse)
async def delete_document(request: DocumentDeleteRequest):
    """
    ë¬¸ì„œ ì‚­ì œ (ì—¬ëŸ¬ content_name ê¸°ì¤€) - Saga Pattern ì ìš©
    
    PostgreSQLê³¼ Milvusì—ì„œ ì—¬ëŸ¬ ë¬¸ì„œì™€ ëª¨ë“  ì²­í¬ë¥¼ ì¼ê´„ ì‚­ì œí•©ë‹ˆë‹¤.
    - content_names ë¦¬ìŠ¤íŠ¸ë¡œ ì—¬ëŸ¬ ë¬¸ì„œ ì‹ë³„
    - Milvus: content_namesì™€ chat_bot_idë¡œ í•„í„°ë§í•˜ì—¬ ëª¨ë“  ë²¡í„° ì‚­ì œ (ë¨¼ì €)
    - PostgreSQL: í•´ë‹¹ íŒŒí‹°ì…˜ì—ì„œ ì—¬ëŸ¬ ë¬¸ì„œì™€ ëª¨ë“  ì²­í¬ ì‚­ì œ (ë‚˜ì¤‘ì—)
    - PostgreSQL ì‹¤íŒ¨ ì‹œ Milvus ë³µêµ¬ (ë³´ìƒ íŠ¸ëœì­ì…˜)
    - ìë™ flushë¡œ ì‹¤ì‹œê°„ ë°˜ì˜
    
    Saga Pattern ì¥ì :
    - ë°ì´í„° ì¼ê´€ì„± ë³´ì¥
    - ë¶€ë¶„ ì‹¤íŒ¨ ì‹œ ìë™ ë³µêµ¬
    - ì—¬ëŸ¬ ë¬¸ì„œ ì¼ê´„ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ í–¥ìƒ
    - POST ë©”ì„œë“œë¡œ ìš”ì²­ ë³¸ë¬¸ì— ì•ˆì „í•˜ê²Œ ë°ì´í„° ì „ë‹¬
    """
    try:
        start_time = datetime.now()
        collection_name = f"collection_{request.account_name}"
        
        logger.info(f"ğŸ—‘ï¸ ë¬¸ì„œ ì¼ê´„ ì‚­ì œ ì‹œì‘ (Saga Pattern)")
        logger.info(f"   - Account: {request.account_name}")
        logger.info(f"   - Bot ID: {request.chat_bot_id}")
        logger.info(f"   - Content Names: {len(request.content_names)}ê°œ")
        logger.info(f"   - Collection: {collection_name}")
        
        # ========== Step 0: ì¡´ì¬í•˜ëŠ” ë¬¸ì„œë§Œ í•„í„°ë§ ==========
        existing_content_names = await postgres_client.get_existing_content_names(
            request.account_name, request.chat_bot_id, request.content_names
        )
        
        if not existing_content_names:
            # ì¡´ì¬í•˜ëŠ” ë¬¸ì„œê°€ ì—†ìŒ
            logger.warning(f"âš ï¸ ì¡´ì¬í•˜ëŠ” ë¬¸ì„œê°€ ì—†ìŒ: {request.content_names}")
            return DocumentDeleteResponse(
                status="success",
                message=f"No documents found to delete from {len(request.content_names)} requested",
                total_requested=len(request.content_names),
                total_success=0,
                total_failed=len(request.content_names),
                successful_content_names=[],
                failed_content_names=request.content_names,
                deleted_documents=0,
                deleted_chunks=0,
                deleted_vectors=0,
                postgres_delete_time_ms=0.0,
                milvus_delete_time_ms=0.0,
                total_time_ms=(datetime.now() - start_time).total_seconds() * 1000
            )
        
        # ì„±ê³µ/ì‹¤íŒ¨í•œ ë¬¸ì„œ ì¶”ì 
        successful_content_names = []
        failed_content_names = []
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë¬¸ì„œë“¤ì„ ì‹¤íŒ¨ ëª©ë¡ì— ì¶”ê°€
        if len(existing_content_names) < len(request.content_names):
            missing_docs = set(request.content_names) - set(existing_content_names)
            failed_content_names.extend(list(missing_docs))
            logger.info(f"ğŸ“‹ ì¡´ì¬í•˜ëŠ” ë¬¸ì„œ: {len(existing_content_names)}ê°œ / {len(request.content_names)}ê°œ")
            logger.info(f"   - ì¡´ì¬í•˜ëŠ” ë¬¸ì„œ: {existing_content_names}")
            logger.info(f"   - ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë¬¸ì„œ: {list(missing_docs)}")
        else:
            logger.info(f"ğŸ“‹ ëª¨ë“  ë¬¸ì„œ ì¡´ì¬: {len(existing_content_names)}ê°œ")
            logger.info(f"   - ì¡´ì¬í•˜ëŠ” ë¬¸ì„œ: {existing_content_names}")
        
        # ========== Step 1: Milvusì—ì„œ ë²¡í„° ì¼ê´„ ì‚­ì œ (ë¨¼ì €) ==========
        milvus_start = datetime.now()
        deleted_vectors = 0
        
        try:
            # ì¡´ì¬í•˜ëŠ” content_nameê³¼ chat_bot_idë¡œ ì¼ê´„ ì‚­ì œ
            deleted_vectors = await milvus_client.delete_by_content_names(
                collection_name, request.chat_bot_id, existing_content_names
            )
            
            milvus_time = (datetime.now() - milvus_start).total_seconds() * 1000
            logger.info(f"âœ… Milvus ì¼ê´„ ì‚­ì œ ì™„ë£Œ: {deleted_vectors}ê°œ ë²¡í„°, {milvus_time:.2f}ms")
            
        except Exception as milvus_error:
            logger.error(f"âŒ Milvus ì¼ê´„ ì‚­ì œ ì‹¤íŒ¨: {str(milvus_error)}")
            # Milvus ì‚­ì œ ì‹¤íŒ¨ ì‹œ ëª¨ë“  ì¡´ì¬í•˜ëŠ” ë¬¸ì„œë¥¼ ì‹¤íŒ¨ ëª©ë¡ì— ì¶”ê°€
            failed_content_names.extend(existing_content_names)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Milvus batch deletion failed: {str(milvus_error)}"
            )
        
        # ========== Step 2: PostgreSQLì—ì„œ ë¬¸ì„œ ì¼ê´„ ì‚­ì œ (ë‚˜ì¤‘ì—) ==========
        postgres_start = datetime.now()
        
        try:
            deleted_docs, deleted_chunks = await postgres_client.delete_documents_by_content_names(
                request.account_name, request.chat_bot_id, existing_content_names
            )
            postgres_time = (datetime.now() - postgres_start).total_seconds() * 1000
            
            logger.info(f"âœ… PostgreSQL ì¼ê´„ ì‚­ì œ ì™„ë£Œ: {deleted_docs}ê°œ ë¬¸ì„œ, {deleted_chunks}ê°œ ì²­í¬, {postgres_time:.2f}ms")
            
            # PostgreSQL ì‚­ì œ ì„±ê³µ ì‹œ ëª¨ë“  ì¡´ì¬í•˜ëŠ” ë¬¸ì„œë¥¼ ì„±ê³µ ëª©ë¡ì— ì¶”ê°€
            successful_content_names.extend(existing_content_names)
            
        except Exception as postgres_error:
            # PostgreSQL ì‚­ì œ ì‹¤íŒ¨ ì‹œ Milvus ë³µêµ¬ (ë³´ìƒ íŠ¸ëœì­ì…˜)
            logger.error(f"âŒ PostgreSQL ì¼ê´„ ì‚­ì œ ì‹¤íŒ¨, Milvus ë³µêµ¬ ì‹œì‘: {str(postgres_error)}")
            try:
                # TODO: Milvus ë³µêµ¬ ë¡œì§ êµ¬í˜„ (ì‚­ì œëœ ë²¡í„°ë¥¼ ë‹¤ì‹œ ì‚½ì…)
                logger.warning(f"âš ï¸ Milvus ë³µêµ¬ ë¡œì§ ë¯¸êµ¬í˜„ - ë°ì´í„° ì¼ê´€ì„± ë¬¸ì œ ê°€ëŠ¥ì„±")
            except Exception as recovery_error:
                logger.error(f"âŒ Milvus ë³µêµ¬ ì‹¤íŒ¨: {str(recovery_error)}")
            
            # PostgreSQL ì‚­ì œ ì‹¤íŒ¨ ì‹œ ëª¨ë“  ì¡´ì¬í•˜ëŠ” ë¬¸ì„œë¥¼ ì‹¤íŒ¨ ëª©ë¡ì— ì¶”ê°€
            failed_content_names.extend(existing_content_names)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"PostgreSQL batch deletion failed: {str(postgres_error)}"
            )
        
        # ========== Step 3: ğŸ”¥ ìë™ flush ë§ˆí‚¹ (ì‚­ì œ ì´ë²¤íŠ¸) ==========
        await auto_flusher.mark_for_flush(collection_name)
        logger.info(f"ğŸ”¥ Flush marked after delete: {collection_name}")
        
        # ========== Step 4: ê²°ê³¼ ë°˜í™˜ ==========
        total_time = (datetime.now() - start_time).total_seconds() * 1000
        
        # ì‘ë‹µ ë©”ì‹œì§€ ìƒì„±
        if len(successful_content_names) == len(request.content_names):
            # ëª¨ë“  ë¬¸ì„œê°€ ì„±ê³µí•œ ê²½ìš°
            status = "success"
            message = f"All {len(request.content_names)} documents deleted successfully"
        elif len(successful_content_names) > 0:
            # ì¼ë¶€ ë¬¸ì„œë§Œ ì„±ê³µí•œ ê²½ìš°
            status = "partial_success"
            message = f"Deleted {len(successful_content_names)} out of {len(request.content_names)} requested documents"
        else:
            # ëª¨ë“  ë¬¸ì„œê°€ ì‹¤íŒ¨í•œ ê²½ìš°
            status = "failed"
            message = f"Failed to delete any of {len(request.content_names)} requested documents"
        
        logger.info(f"âœ… ë¬¸ì„œ ì¼ê´„ ì‚­ì œ ì™„ë£Œ (Saga Pattern ì„±ê³µ)")
        logger.info(f"   - ìš”ì²­ëœ ë¬¸ì„œ: {len(request.content_names)}ê°œ")
        logger.info(f"   - ì„±ê³µí•œ ë¬¸ì„œ: {len(successful_content_names)}ê°œ")
        logger.info(f"   - ì‹¤íŒ¨í•œ ë¬¸ì„œ: {len(failed_content_names)}ê°œ")
        logger.info(f"   - ì‚­ì œëœ ë¬¸ì„œ: {deleted_docs}ê°œ")
        logger.info(f"   - ì‚­ì œëœ ì²­í¬: {deleted_chunks}ê°œ")
        logger.info(f"   - ì‚­ì œëœ ë²¡í„°: {deleted_vectors}ê°œ")
        logger.info(f"   - ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ms")
        logger.info(f"   - ê²€ìƒ‰ì—ì„œ ì œì™¸: 0.5ì´ˆ ì´ë‚´")
        
        return DocumentDeleteResponse(
            status=status,
            message=message,
            total_requested=len(request.content_names),
            total_success=len(successful_content_names),
            total_failed=len(failed_content_names),
            successful_content_names=successful_content_names,
            failed_content_names=failed_content_names,
            deleted_documents=deleted_docs,
            deleted_chunks=deleted_chunks,
            deleted_vectors=deleted_vectors,
            postgres_delete_time_ms=postgres_time,
            milvus_delete_time_ms=milvus_time,
            total_time_ms=total_time
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ë¬¸ì„œ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to delete document: {str(e)}"
        )


@router.post("/bot/delete", response_model=BotDeleteResponse, status_code=status.HTTP_200_OK)
async def delete_bot_data(request: BotDeleteRequest):
    """
    ë´‡ ì „ì²´ ë°ì´í„° ì‚­ì œ (chat_bot_id ê¸°ì¤€) - Saga Pattern ì ìš©
    
    í•´ë‹¹ ë´‡ì˜ ëª¨ë“  ë¬¸ì„œì™€ ì²­í¬ë¥¼ PostgreSQLê³¼ Milvusì—ì„œ ì‚­ì œí•©ë‹ˆë‹¤.
    - Milvus: í•´ë‹¹ íŒŒí‹°ì…˜ì˜ ëª¨ë“  ë²¡í„° ì‚­ì œ (ë¨¼ì €)
    - PostgreSQL: í•´ë‹¹ ë´‡ì˜ ëª¨ë“  ë¬¸ì„œì™€ ì²­í¬ ì‚­ì œ (ë‚˜ì¤‘ì—)
    - PostgreSQL ì‹¤íŒ¨ ì‹œ Milvus ë³µêµ¬ (ë³´ìƒ íŠ¸ëœì­ì…˜)
    - ìë™ flushë¡œ ì‹¤ì‹œê°„ ë°˜ì˜
    
    Saga Pattern ì¥ì :
    - ë°ì´í„° ì¼ê´€ì„± ë³´ì¥
    - ë¶€ë¶„ ì‹¤íŒ¨ ì‹œ ìë™ ë³µêµ¬
    - POST ë©”ì„œë“œë¡œ ìš”ì²­ ë³¸ë¬¸ì— ì•ˆì „í•˜ê²Œ ë°ì´í„° ì „ë‹¬
    """
    try:
        start_time = datetime.now()
        
        logger.info(f"ğŸ—‘ï¸ ë´‡ ì „ì²´ ì‚­ì œ ì‹œì‘ (Saga Pattern)")
        logger.info(f"   - Account: {request.account_name}")
        logger.info(f"   - Bot ID: {request.chat_bot_id}")
        
        collection_name = f"collection_{request.account_name}"
        partition_name = generate_partition_name(request.chat_bot_id)
        
        # ========== Step 1: Milvusì—ì„œ íŒŒí‹°ì…˜ ì‚­ì œ (ë¨¼ì €) ==========
        milvus_start = datetime.now()
        deleted_vectors = 0
        
        try:
            # Milvusì—ì„œ í•´ë‹¹ íŒŒí‹°ì…˜ì˜ ëª¨ë“  ë²¡í„° ì‚­ì œ
            deleted_vectors = await milvus_client.delete_partition(collection_name, partition_name)
            
            milvus_time = (datetime.now() - milvus_start).total_seconds() * 1000
            logger.info(f"âœ… Milvus íŒŒí‹°ì…˜ ì‚­ì œ ì™„ë£Œ: {deleted_vectors}ê°œ ë²¡í„°, {milvus_time:.2f}ms")
            
        except Exception as milvus_error:
            logger.error(f"âŒ Milvus íŒŒí‹°ì…˜ ì‚­ì œ ì‹¤íŒ¨: {str(milvus_error)}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Milvus partition deletion failed: {str(milvus_error)}"
            )
        
        # ========== Step 2: PostgreSQLì—ì„œ ë´‡ ë°ì´í„° ì‚­ì œ (ë‚˜ì¤‘ì—) ==========
        postgres_start = datetime.now()
        
        try:
            deleted_docs, deleted_chunks = await postgres_client.delete_bot_data(request.account_name, request.chat_bot_id)
            postgres_time = (datetime.now() - postgres_start).total_seconds() * 1000
            logger.info(f"âœ… PostgreSQL ë´‡ ì‚­ì œ ì™„ë£Œ: {deleted_docs}ê°œ ë¬¸ì„œ, {deleted_chunks}ê°œ ì²­í¬, {postgres_time:.2f}ms")
            
        except Exception as postgres_error:
            # PostgreSQL ì‚­ì œ ì‹¤íŒ¨ ì‹œ Milvus ë³µêµ¬ (ë³´ìƒ íŠ¸ëœì­ì…˜)
            logger.error(f"âŒ PostgreSQL ë´‡ ì‚­ì œ ì‹¤íŒ¨, Milvus ë³µêµ¬ ì‹œì‘: {str(postgres_error)}")
            try:
                # TODO: Milvus ë³µêµ¬ ë¡œì§ êµ¬í˜„ (ì‚­ì œëœ íŒŒí‹°ì…˜ì„ ë‹¤ì‹œ ìƒì„±í•˜ê³  ë²¡í„° ì¬ì‚½ì…)
                # í˜„ì¬ëŠ” ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ê³„ì† ì§„í–‰
                logger.warning(f"âš ï¸ Milvus ë³µêµ¬ ë¡œì§ ë¯¸êµ¬í˜„ - ë°ì´í„° ì¼ê´€ì„± ë¬¸ì œ ê°€ëŠ¥ì„±")
            except Exception as recovery_error:
                logger.error(f"âŒ Milvus ë³µêµ¬ ì‹¤íŒ¨: {str(recovery_error)}")
            
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"PostgreSQL bot deletion failed: {str(postgres_error)}"
            )
        
        # ========== Step 3: ğŸ”¥ ìë™ flush ë§ˆí‚¹ (ì‚­ì œ ì´ë²¤íŠ¸) ==========
        await auto_flusher.mark_for_flush(collection_name)
        logger.info(f"ğŸ”¥ Flush marked after bot delete: {collection_name}")
        
        # ========== Step 4: ê²°ê³¼ ë°˜í™˜ ==========
        total_time = (datetime.now() - start_time).total_seconds() * 1000
        
        logger.info(f"âœ… ë´‡ ì „ì²´ ì‚­ì œ ì™„ë£Œ (Saga Pattern ì„±ê³µ)")
        logger.info(f"   - Bot ID: {request.chat_bot_id}")
        logger.info(f"   - ì‚­ì œëœ ë¬¸ì„œ: {deleted_docs}ê°œ")
        logger.info(f"   - ì‚­ì œëœ ì²­í¬: {deleted_chunks}ê°œ")
        logger.info(f"   - ì‚­ì œëœ ë²¡í„°: {deleted_vectors}ê°œ")
        logger.info(f"   - ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ms")
        logger.info(f"   - ê²€ìƒ‰ì—ì„œ ì œì™¸: 0.5ì´ˆ ì´ë‚´")
        
        return BotDeleteResponse(
            status="success",
            chat_bot_id=request.chat_bot_id,
            deleted_documents=deleted_docs,
            deleted_chunks=deleted_chunks,
            deleted_vectors=deleted_vectors,
            postgres_delete_time_ms=postgres_time,
            milvus_delete_time_ms=milvus_time,
            total_time_ms=total_time
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ë´‡ ì „ì²´ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to delete bot data: {str(e)}"
        )


@router.patch("/document/{doc_id}/metadata", response_model=MetadataUpdateResponse)
async def update_metadata(doc_id: int, request: MetadataUpdateRequest):
    """
    ë©”íƒ€ë°ì´í„°ë§Œ ì—…ë°ì´íŠ¸
    
    PostgreSQLë§Œ ìˆ˜ì •í•˜ê³  MilvusëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ (ì´ˆê³ ì†)
    """
    try:
        logger.info(f"ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ìš”ì²­ (account: {request.account_name}, bot: {request.chat_bot_id}): doc_id={doc_id}")
        
        # TODO: PostgreSQL UPDATEë§Œ ì‹¤í–‰ (í•´ë‹¹ íŒŒí‹°ì…˜ì—ì„œë§Œ)
        # await postgres_client.update_metadata(request.account_name, request.chat_bot_id, doc_id, request.metadata_updates)
        
        raise HTTPException(
            status_code=status.HTTP_501_NOT_IMPLEMENTED,
            detail="êµ¬í˜„ ì˜ˆì •"
        )
    except Exception as e:
        logger.error(f"ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to update metadata: {str(e)}"
        )





